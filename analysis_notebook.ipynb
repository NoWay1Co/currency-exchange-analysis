{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Анализ данных мошенничества в банковских транзакциях\n",
        "\n",
        "## Цель анализа\n",
        "Провести комплексный анализ данных транзакций (7.5M записей) \n",
        "для выявления паттернов мошенничества и предоставления банку ценных инсайтов для:\n",
        "- Снижения финансовых потерь от мошенничества на 25-40%\n",
        "- Улучшения customer experience через снижение false positive на 40-60%\n",
        "- Оптимизации загрузки серверов на основе временных и географических паттернов\n",
        "- Повышения точности обнаружения мошеннических операций с 85% до 92-95%\n",
        "\n",
        "## Структура анализа\n",
        "1. **Препроцессинг данных** - очистка и подготовка данных\n",
        "2. **Исследовательский анализ данных (EDA)** - изучение распределений и аномалий\n",
        "3. **Временной и географический анализ** - паттерны активности и мошенничества\n",
        "4. **Выводы и рекомендации** - бизнес-инсайты для банка\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'squarify'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msubplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_subplots\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfigure_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mff\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msquarify\u001b[39;00m  \u001b[38;5;66;03m# для treemap\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlifelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KaplanMeierFitter  \u001b[38;5;66;03m# для survival analysis\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'squarify'"
          ]
        }
      ],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff\n",
        "import squarify  # для treemap\n",
        "from lifelines import KaplanMeierFitter  # для survival analysis\n",
        "from scipy import stats\n",
        "import networkx as nx  # для network analysis\n",
        "\n",
        "# Настройки для отображения\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Безопасная настройка стиля matplotlib\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except OSError:\n",
        "    try:\n",
        "        plt.style.use('seaborn')\n",
        "    except OSError:\n",
        "        plt.style.use('default')\n",
        "        print(\"Используется стандартный стиль matplotlib\")\n",
        "\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Настройки pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "\n",
        "print(\"Библиотеки успешно импортированы\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "print(\"Загружаем данные о мошенничестве...\")\n",
        "\n",
        "# Загрузка основного датасета\n",
        "df = pd.read_parquet('data/transaction_fraud_data.parquet')\n",
        "\n",
        "# Загрузка данных по валютным курсам\n",
        "currency_data = pd.read_parquet('data/historical_currency_exchange.parquet')\n",
        "\n",
        "# Функция для конвертации валют в USD\n",
        "def convert_to_usd(df, currency_rates):\n",
        "    \"\"\"Конвертация amount в USD с использованием курсов валют\"\"\"\n",
        "    df_converted = df.copy()\n",
        "    \n",
        "    # Создаем словарь курсов валют (используем последние доступные курсы)\n",
        "    latest_rates = currency_rates.iloc[-1]  # Последняя дата\n",
        "    \n",
        "    # Маппинг стран к валютам\n",
        "    country_currency_map = {\n",
        "        'Nigeria': 'NGN',\n",
        "        'Brazil': 'BRL', \n",
        "        'Russia': 'RUB',\n",
        "        'Mexico': 'MXN',\n",
        "        'Singapore': 'SGD',\n",
        "        'Canada': 'CAD',\n",
        "        'Australia': 'AUD',\n",
        "        'United Kingdom': 'GBP',\n",
        "        'European Union': 'EUR',\n",
        "        'Japan': 'JPY',\n",
        "        'USA': 'USD'\n",
        "    }\n",
        "    \n",
        "    # Создаем столбец amount_usd\n",
        "    df_converted['amount_usd'] = df_converted['amount'].copy()\n",
        "    \n",
        "    for country, currency_code in country_currency_map.items():\n",
        "        if country in df_converted['country'].values and currency_code in latest_rates.index:\n",
        "            mask = df_converted['country'] == country\n",
        "            if currency_code != 'USD':\n",
        "                # Конвертируем в USD\n",
        "                exchange_rate = latest_rates[currency_code]\n",
        "                df_converted.loc[mask, 'amount_usd'] = df_converted.loc[mask, 'amount'] / exchange_rate\n",
        "                print(f\"Конвертирован {country}: {currency_code} -> USD (курс: {exchange_rate:.4f})\")\n",
        "            else:\n",
        "                print(f\"{country}: уже в USD\")\n",
        "    \n",
        "    return df_converted\n",
        "\n",
        "# Применяем конвертацию валют\n",
        "df = convert_to_usd(df, currency_data)\n",
        "\n",
        "print(f\"Данные успешно загружены!\")\n",
        "print(f\"Размер основного датасета: {df.shape[0]:,} строк, {df.shape[1]} столбцов\")\n",
        "print(f\"Размер данных по курсам валют: {currency_data.shape[0]:,} строк, {currency_data.shape[1]} столбцов\")\n",
        "\n",
        "print(\"\\nСтолбцы в основном датасете:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\nПервые 3 строки:\")\n",
        "print(df.head(3))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ЭТАП 1: ПРЕПРОЦЕССИНГ ДАННЫХ\n",
        "\n",
        "## Задача 1.1: Первичный анализ данных\n",
        "- Анализ структуры данных и типов столбцов\n",
        "- Выявление пропущенных значений\n",
        "- Базовая статистика по датасету\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Первичный анализ данных\n",
        "def analyze_dataset(df):\n",
        "    \"\"\"Функция для первичного анализа датасета\"\"\"\n",
        "    print(\"=== БАЗОВАЯ ИНФОРМАЦИЯ О ДАТАСЕТЕ ===\")\n",
        "    print(f\"Размер датасета: {df.shape[0]:,} строк, {df.shape[1]} столбцов\")\n",
        "    print(f\"Объем данных в памяти: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    print(\"\\n=== ТИПЫ ДАННЫХ ===\")\n",
        "    print(df.dtypes)\n",
        "    \n",
        "    print(\"\\n=== ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ ===\")\n",
        "    missing_data = df.isnull().sum()\n",
        "    missing_percent = (missing_data / len(df)) * 100\n",
        "    missing_info = pd.DataFrame({\n",
        "        'Пропущенные значения': missing_data,\n",
        "        'Процент': missing_percent\n",
        "    }).sort_values('Пропущенные значения', ascending=False)\n",
        "    print(missing_info[missing_info['Пропущенные значения'] > 0])\n",
        "    \n",
        "    print(\"\\n=== ПЕРВЫЕ 5 СТРОК ===\")\n",
        "    print(df.head())\n",
        "    \n",
        "    return missing_info\n",
        "\n",
        "# Запуск анализа данных\n",
        "missing_info = analyze_dataset(df)\n",
        "\n",
        "print(\"Анализ данных завершен.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Задача 1.2: Анализ информативности столбцов\n",
        "- Анализ уникальности device_fingerprint (вероятно неинформативен)\n",
        "- Проверка паттернов в ip_address (вероятно неинформативен)\n",
        "- Оценка информативности transaction_id, customer_id, card_number\n",
        "- Создание списка столбцов для удаления\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ информативности столбцов\n",
        "def analyze_column_informativeness(df):\n",
        "    \"\"\"Анализ информативности столбцов для принятия решения об удалении\"\"\"\n",
        "    \n",
        "    # Проверяем какие столбцы есть в данных\n",
        "    available_analysis_columns = ['device_fingerprint', 'ip_address', 'transaction_id', \n",
        "                                 'customer_id', 'card_number']\n",
        "    columns_to_analyze = [col for col in available_analysis_columns if col in df.columns]\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    print(\"=== АНАЛИЗ ИНФОРМАТИВНОСТИ СТОЛБЦОВ ===\\n\")\n",
        "    \n",
        "    for col in columns_to_analyze:\n",
        "        if col in df.columns:\n",
        "            unique_count = df[col].nunique()\n",
        "            total_count = len(df)\n",
        "            unique_ratio = unique_count / total_count\n",
        "            \n",
        "            print(f\"СТОЛБЕЦ: {col}\")\n",
        "            print(f\"  Уникальных значений: {unique_count:,} из {total_count:,}\")\n",
        "            print(f\"  Доля уникальных: {unique_ratio:.4f} ({unique_ratio*100:.2f}%)\")\n",
        "            \n",
        "            # Анализ информативности\n",
        "            if unique_ratio > 0.95:\n",
        "                recommendation = \"УДАЛИТЬ - слишком высокая уникальность\"\n",
        "            elif unique_ratio < 0.01:\n",
        "                recommendation = \"УДАЛИТЬ - слишком низкая вариативность\"\n",
        "            else:\n",
        "                recommendation = \"ОСТАВИТЬ - потенциально информативен\"\n",
        "            \n",
        "            print(f\"  Рекомендация: {recommendation}\")\n",
        "            \n",
        "            # Примеры значений\n",
        "            print(f\"  Примеры значений: {df[col].head(3).tolist()}\")\n",
        "            print()\n",
        "            \n",
        "            results[col] = {\n",
        "                'unique_count': unique_count,\n",
        "                'unique_ratio': unique_ratio,\n",
        "                'recommendation': recommendation\n",
        "            }\n",
        "        else:\n",
        "            print(f\"Столбец {col} не найден в данных\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Создание функции для удаления неинформативных столбцов\n",
        "def remove_uninformative_columns(df, columns_analysis):\n",
        "    \"\"\"Удаление неинформативных столбцов на основе анализа\"\"\"\n",
        "    columns_to_remove = []\n",
        "    \n",
        "    for col, analysis in columns_analysis.items():\n",
        "        if \"УДАЛИТЬ\" in analysis['recommendation']:\n",
        "            columns_to_remove.append(col)\n",
        "    \n",
        "    print(f\"Столбцы для удаления: {columns_to_remove}\")\n",
        "    \n",
        "    if columns_to_remove:\n",
        "        df_cleaned = df.drop(columns=columns_to_remove)\n",
        "        print(f\"Размер данных до очистки: {df.shape}\")\n",
        "        print(f\"Размер данных после очистки: {df_cleaned.shape}\")\n",
        "        return df_cleaned, columns_to_remove\n",
        "    else:\n",
        "        print(\"Столбцы для удаления не найдены\")\n",
        "        return df, []\n",
        "\n",
        "# Запуск анализа информативности столбцов\n",
        "columns_analysis = analyze_column_informativeness(df)\n",
        "df_cleaned, removed_columns = remove_uninformative_columns(df, columns_analysis)\n",
        "\n",
        "print(\"Анализ информативности завершен\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Задача 1.3: Создание дополнительных признаков\n",
        "- Извлечение часа дня из timestamp для анализа временных паттернов\n",
        "- Создание дня недели из timestamp\n",
        "- Добавление признака \"размер транзакции\" (категориальный на основе amount_usd)\n",
        "- Создание соотношений для last_hour_activity метрик\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание дополнительных признаков\n",
        "def create_additional_features(df):\n",
        "    \"\"\"Создание дополнительных признаков для анализа\"\"\"\n",
        "    df_enhanced = df.copy()\n",
        "    \n",
        "    print(\"=== СОЗДАНИЕ ДОПОЛНИТЕЛЬНЫХ ПРИЗНАКОВ ===\")\n",
        "    \n",
        "    # Преобразование timestamp в datetime если нужно\n",
        "    if 'timestamp' in df_enhanced.columns:\n",
        "        if df_enhanced['timestamp'].dtype == 'object':\n",
        "            df_enhanced['timestamp'] = pd.to_datetime(df_enhanced['timestamp'])\n",
        "        \n",
        "        # Извлечение временных признаков\n",
        "        df_enhanced['hour'] = df_enhanced['timestamp'].dt.hour\n",
        "        df_enhanced['day_of_week'] = df_enhanced['timestamp'].dt.dayofweek\n",
        "        df_enhanced['day_name'] = df_enhanced['timestamp'].dt.day_name()\n",
        "        \n",
        "        print(\"✓ Созданы временные признаки: hour, day_of_week, day_name\")\n",
        "    \n",
        "    # Категоризация размера транзакции\n",
        "    # Проверяем наличие столбца amount_usd (после конвертации валют)\n",
        "    amount_col = 'amount_usd' if 'amount_usd' in df_enhanced.columns else 'amount'\n",
        "    \n",
        "    if amount_col in df_enhanced.columns:\n",
        "        # Определение квартилей для категоризации\n",
        "        q25 = df_enhanced[amount_col].quantile(0.25)\n",
        "        q50 = df_enhanced[amount_col].quantile(0.50)\n",
        "        q75 = df_enhanced[amount_col].quantile(0.75)\n",
        "        q95 = df_enhanced[amount_col].quantile(0.95)\n",
        "        \n",
        "        def categorize_transaction_size(amount):\n",
        "            if amount <= q25:\n",
        "                return 'Малая'\n",
        "            elif amount <= q50:\n",
        "                return 'Средняя'\n",
        "            elif amount <= q75:\n",
        "                return 'Большая'\n",
        "            elif amount <= q95:\n",
        "                return 'Очень большая'\n",
        "            else:\n",
        "                return 'Экстремальная'\n",
        "        \n",
        "        df_enhanced['transaction_size_category'] = df_enhanced[amount_col].apply(categorize_transaction_size)\n",
        "        \n",
        "        print(f\"✓ Создан признак transaction_size_category\")\n",
        "        print(f\"  Границы: Малая ≤{q25:.2f}, Средняя ≤{q50:.2f}, Большая ≤{q75:.2f}, Очень большая ≤{q95:.2f}\")\n",
        "    \n",
        "    # Обработка last_hour_activity (в данных это один столбец, возможно JSON/dict)\n",
        "    if 'last_hour_activity' in df_enhanced.columns:\n",
        "        print(\"✓ Найден столбец last_hour_activity\")\n",
        "        # Если это строка JSON, можно попробовать распарсить\n",
        "        try:\n",
        "            # Попробуем извлечь информацию из last_hour_activity\n",
        "            sample_value = df_enhanced['last_hour_activity'].iloc[0]\n",
        "            print(f\"Пример значения last_hour_activity: {sample_value}\")\n",
        "            \n",
        "            # Простые метрики на основе last_hour_activity\n",
        "            df_enhanced['has_hour_activity'] = df_enhanced['last_hour_activity'].notna().astype(int)\n",
        "            print(\"✓ Создан признак has_hour_activity\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Не удалось обработать last_hour_activity: {e}\")\n",
        "    \n",
        "    # Соотношение с текущей транзакцией (используем правильное название столбца)\n",
        "    if amount_col in df_enhanced.columns:\n",
        "        # Создаем логарифм суммы в USD для корректного анализа\n",
        "        df_enhanced['amount_log'] = np.log1p(df_enhanced[amount_col])\n",
        "        print(f\"✓ Создан признак amount_log на основе {amount_col}\")\n",
        "        \n",
        "        # Добавляем информацию о валютах после конвертации\n",
        "        if amount_col == 'amount_usd':\n",
        "            print(\"✓ amount_log создан на основе USD - все суммы сконвертированы для корректного сравнения\")\n",
        "        else:\n",
        "            print(\"⚠️ ВНИМАНИЕ: amount_log создан на основе исходных валют, не USD!\")\n",
        "    \n",
        "    # Признак времени суток\n",
        "    if 'hour' in df_enhanced.columns:\n",
        "        def get_time_period(hour):\n",
        "            if 6 <= hour < 12:\n",
        "                return 'Утро'\n",
        "            elif 12 <= hour < 18:\n",
        "                return 'День'\n",
        "            elif 18 <= hour < 22:\n",
        "                return 'Вечер'\n",
        "            else:\n",
        "                return 'Ночь'\n",
        "        \n",
        "        df_enhanced['time_period'] = df_enhanced['hour'].apply(get_time_period)\n",
        "        print(\"✓ Создан признак time_period\")\n",
        "    \n",
        "    print(f\"\\nРазмер данных: {df_enhanced.shape}\")\n",
        "    print(f\"Добавлено признаков: {df_enhanced.shape[1] - df.shape[1]}\")\n",
        "    \n",
        "    return df_enhanced\n",
        "\n",
        "# Запуск создания дополнительных признаков\n",
        "df_with_features = create_additional_features(df_cleaned)\n",
        "\n",
        "print(\"Создание признаков завершено\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ЭТАП 2: ИССЛЕДОВАТЕЛЬСКИЙ АНАЛИЗ ДАННЫХ (EDA)\n",
        "\n",
        "## Задача 2.1: Анализ распределения целевой переменной\n",
        "- График распределения is_fraud (количество и проценты)\n",
        "- Таблица с точными значениями и долями\n",
        "- Анализ потенциального class imbalance\n",
        "- Fraud rate по времени (тренды)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ распределения целевой переменной\n",
        "def analyze_target_variable(df):\n",
        "    \"\"\"Анализ распределения целевой переменной is_fraud\"\"\"\n",
        "    \n",
        "    if 'is_fraud' not in df.columns:\n",
        "        print(\"Столбец 'is_fraud' не найден в данных\")\n",
        "        return\n",
        "    \n",
        "    print(\"=== АНАЛИЗ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ ===\")\n",
        "    \n",
        "    # Основная статистика\n",
        "    fraud_counts = df['is_fraud'].value_counts()\n",
        "    fraud_percentages = df['is_fraud'].value_counts(normalize=True) * 100\n",
        "    \n",
        "    # Таблица с результатами\n",
        "    fraud_summary = pd.DataFrame({\n",
        "        'Количество': fraud_counts,\n",
        "        'Процент': fraud_percentages\n",
        "    })\n",
        "    fraud_summary.index = ['Легитимные', 'Мошеннические']\n",
        "    \n",
        "    print(\"РАСПРЕДЕЛЕНИЕ ТРАНЗАКЦИЙ:\")\n",
        "    print(fraud_summary)\n",
        "    \n",
        "    # Создание графиков\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    \n",
        "    # График 1: Столбчатая диаграмма количества\n",
        "    fraud_counts.plot(kind='bar', ax=axes[0], color=['skyblue', 'salmon'])\n",
        "    axes[0].set_title('Распределение транзакций по типу')\n",
        "    axes[0].set_xlabel('Тип транзакции')\n",
        "    axes[0].set_ylabel('Количество')\n",
        "    axes[0].set_xticklabels(['Легитимные', 'Мошеннические'], rotation=0)\n",
        "    \n",
        "    # Добавление значений на столбцы\n",
        "    for i, v in enumerate(fraud_counts.values):\n",
        "        axes[0].text(i, v + max(fraud_counts) * 0.01, f'{v:,}', ha='center')\n",
        "    \n",
        "    # График 2: Круговая диаграмма\n",
        "    axes[1].pie(fraud_counts.values, labels=['Легитимные', 'Мошеннические'], \n",
        "                autopct='%1.2f%%', colors=['skyblue', 'salmon'])\n",
        "    axes[1].set_title('Доля мошеннических транзакций')\n",
        "    \n",
        "    # График 3: Доля мошенничества\n",
        "    fraud_rate = fraud_percentages[1]\n",
        "    axes[2].bar(['Fraud Rate'], [fraud_rate], color='salmon', alpha=0.7)\n",
        "    axes[2].set_ylim(0, 100)\n",
        "    axes[2].set_title(f'Процент мошенничества: {fraud_rate:.3f}%')\n",
        "    axes[2].set_ylabel('Процент мошеннических транзакций (меньше лучше)')\n",
        "    \n",
        "    # Добавление значения на столбец\n",
        "    axes[2].text(0, fraud_rate + 2, f'{fraud_rate:.3f}%', ha='center')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Анализ дисбаланса классов\n",
        "    print(f\"\\nАНАЛИЗ БАЛАНСА КЛАССОВ:\")\n",
        "    print(f\"Соотношение легитимных к мошенническим: {fraud_counts[0] / fraud_counts[1]:.1f}:1\")\n",
        "    \n",
        "    if fraud_rate < 5:\n",
        "        print(f\"СИЛЬНЫЙ ДИСБАЛАНС КЛАССОВ (fraud rate = {fraud_rate:.3f}%)\")\n",
        "        print(\"Рекомендуется использовать техники работы с несбалансированными данными\")\n",
        "    elif fraud_rate < 10:\n",
        "        print(f\"УМЕРЕННЫЙ ДИСБАЛАНС КЛАССОВ (fraud rate = {fraud_rate:.3f}%)\")\n",
        "    else:\n",
        "        print(f\"ОТНОСИТЕЛЬНО СБАЛАНСИРОВАННЫЕ КЛАССЫ (fraud rate = {fraud_rate:.3f}%)\")\n",
        "    \n",
        "    return fraud_summary\n",
        "\n",
        "# Анализ fraud rate по времени\n",
        "def analyze_fraud_trends_over_time(df):\n",
        "    \"\"\"Анализ трендов мошенничества по времени\"\"\"\n",
        "    \n",
        "    if 'timestamp' not in df.columns or 'is_fraud' not in df.columns:\n",
        "        print(\"Необходимые столбцы 'timestamp' и 'is_fraud' не найдены\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\n=== ТРЕНДЫ МОШЕННИЧЕСТВА ПО ВРЕМЕНИ ===\")\n",
        "    \n",
        "    # Подготовка данных\n",
        "    df_time = df.copy()\n",
        "    df_time['date'] = df_time['timestamp'].dt.date\n",
        "    \n",
        "    # Группировка по датам\n",
        "    daily_stats = df_time.groupby('date').agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    \n",
        "    daily_stats.columns = ['date', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "    daily_stats['fraud_rate'] = daily_stats['fraud_rate'] * 100\n",
        "    \n",
        "    # График тренда\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "    \n",
        "    # График 1: Количество транзакций и мошенничества по дням (реальные значения)\n",
        "    axes[0].plot(daily_stats['date'], daily_stats['total_transactions'], \n",
        "                label='Общее количество транзакций', color='blue', alpha=0.7, linewidth=2)\n",
        "    \n",
        "    # Создаем вторую ось Y для мошеннических транзакций (реальные значения)\n",
        "    ax0_twin = axes[0].twinx()\n",
        "    ax0_twin.plot(daily_stats['date'], daily_stats['fraud_count'], \n",
        "                  label='Мошеннические транзакции', color='red', alpha=0.7, linewidth=2)\n",
        "    \n",
        "    axes[0].set_ylabel('Общее количество транзакций', color='blue')\n",
        "    ax0_twin.set_ylabel('Мошеннические транзакции (реальные значения)', color='red')\n",
        "    axes[0].tick_params(axis='y', labelcolor='blue')\n",
        "    ax0_twin.tick_params(axis='y', labelcolor='red')\n",
        "    \n",
        "    axes[0].set_title('Динамика транзакций по дням (реальные значения)')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Добавляем легенды\n",
        "    axes[0].legend(loc='upper left')\n",
        "    ax0_twin.legend(loc='upper right')\n",
        "    \n",
        "    # График 2: Fraud rate по дням\n",
        "    axes[1].plot(daily_stats['date'], daily_stats['fraud_rate'], \n",
        "                color='orange', marker='o', markersize=3)\n",
        "    axes[1].set_title('Динамика процента мошенничества по дням')\n",
        "    axes[1].set_ylabel('Fraud Rate (%)')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Статистика по трендам\n",
        "    print(f\"Средний fraud rate: {daily_stats['fraud_rate'].mean():.3f}%\")\n",
        "    print(f\"Минимальный fraud rate: {daily_stats['fraud_rate'].min():.3f}%\")\n",
        "    print(f\"Максимальный fraud rate: {daily_stats['fraud_rate'].max():.3f}%\")\n",
        "    print(f\"Стандартное отклонение fraud rate: {daily_stats['fraud_rate'].std():.3f}%\")\n",
        "    \n",
        "    return daily_stats\n",
        "\n",
        "# Запуск анализа целевой переменной\n",
        "fraud_summary = analyze_target_variable(df_with_features)\n",
        "daily_trends = analyze_fraud_trends_over_time(df_with_features)\n",
        "\n",
        "print(\"Анализ целевой переменной завершен\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Задача 2.2: Анализ распределения ключевых переменных\n",
        "- Histogram + KDE для amount_usd (общее и по is_fraud)\n",
        "- Box plots для amount_usd по странам и каналам\n",
        "- Распределение last_hour_activity.num_transactions\n",
        "- Распределение last_hour_activity.total_amount\n",
        "- Count plots для country, vendor_category, device, channel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ распределения ключевых переменных\n",
        "def analyze_amount_distribution(df):\n",
        "    \"\"\"Анализ распределения сумм транзакций\"\"\"\n",
        "    \n",
        "    # Определяем правильное название столбца (приоритет USD после конвертации)\n",
        "    amount_col = 'amount_usd' if 'amount_usd' in df.columns else 'amount'\n",
        "    \n",
        "    if amount_col not in df.columns:\n",
        "        print(f\"Столбец '{amount_col}' не найден\")\n",
        "        print(f\"Доступные столбцы: {list(df.columns)}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"=== АНАЛИЗ РАСПРЕДЕЛЕНИЯ СУММ ТРАНЗАКЦИЙ ({amount_col}) ===\")\n",
        "    \n",
        "    # Основная статистика\n",
        "    print(f\"ОПИСАТЕЛЬНАЯ СТАТИСТИКА {amount_col}:\")\n",
        "    print(df[amount_col].describe())\n",
        "    \n",
        "    # Создание графиков (убираем один график)\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    \n",
        "    # График 1: Распределение с логарифмической шкалой\n",
        "    df[amount_col].hist(bins=50, alpha=0.7, ax=axes[0])\n",
        "    axes[0].set_yscale('log')\n",
        "    axes[0].set_title(f'Распределение сумм (логарифмическая шкала)')\n",
        "    # Исправляем отображение валюты - все конвертировано в USD\n",
        "    currency_label = \"USD (все валюты сконвертированы)\" if amount_col == 'amount_usd' else \"исходная валюта\"\n",
        "    axes[0].set_xlabel(f'Сумма транзакции ({currency_label})')\n",
        "    axes[0].set_ylabel('Частота транзакций (логарифм)')\n",
        "    \n",
        "    # График 2: Распределение по типу транзакции (если есть is_fraud)\n",
        "    if 'is_fraud' in df.columns:\n",
        "        for fraud_type in [0, 1]:\n",
        "            data = df[df['is_fraud'] == fraud_type][amount_col]\n",
        "            label = 'Мошеннические (хуже)' if fraud_type == 1 else 'Легитимные (лучше)'\n",
        "            data.hist(bins=50, alpha=0.6, ax=axes[1], label=label, density=True)\n",
        "        \n",
        "        axes[1].legend()\n",
        "        axes[1].set_title(f'Сравнение распределения сумм по типу транзакции')\n",
        "        # Исправляем отображение валюты - все конвертировано в USD\n",
        "        axes[1].set_xlabel(f'Сумма транзакции ({currency_label})')\n",
        "        axes[1].set_ylabel('Плотность распределения')\n",
        "    \n",
        "    # График 3: Box plot по квартилям\n",
        "    quartiles = pd.qcut(df[amount_col], q=4, labels=['Q1 (25%)', 'Q2 (50%)', 'Q3 (75%)', 'Q4 (95%)'])\n",
        "    df_with_quartiles = df.copy()\n",
        "    df_with_quartiles['quartile'] = quartiles\n",
        "    sns.boxplot(data=df_with_quartiles, x='quartile', y=amount_col, ax=axes[2])\n",
        "    axes[2].set_title(f'Квартильное распределение сумм транзакций')\n",
        "    axes[2].set_xlabel('Квартили (Q1-малые суммы, Q4-большие суммы)')\n",
        "    axes[2].set_ylabel(f'Сумма транзакции ({amount_col})')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Анализ выбросов\n",
        "    Q1 = df[amount_col].quantile(0.25)\n",
        "    Q3 = df[amount_col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = df[(df[amount_col] < lower_bound) | (df[amount_col] > upper_bound)]\n",
        "    \n",
        "    print(f\"\\nАНАЛИЗ ВЫБРОСОВ:\")\n",
        "    print(f\"Выбросов: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")\n",
        "    print(f\"Верхняя граница: {upper_bound:,.2f}\")\n",
        "    print(f\"Максимальная сумма: {df[amount_col].max():,.2f}\")\n",
        "\n",
        "def analyze_categorical_distributions(df):\n",
        "    \"\"\"Анализ распределения категориальных переменных\"\"\"\n",
        "    \n",
        "    categorical_columns = ['country', 'vendor_category', 'device', 'channel']\n",
        "    available_columns = [col for col in categorical_columns if col in df.columns]\n",
        "    \n",
        "    if not available_columns:\n",
        "        print(\"Категориальные столбцы не найдены\")\n",
        "        return\n",
        "    \n",
        "    print(\"=== АНАЛИЗ КАТЕГОРИАЛЬНЫХ ПЕРЕМЕННЫХ ===\")\n",
        "    \n",
        "    # Создание графиков\n",
        "    n_cols = 2\n",
        "    n_rows = (len(available_columns) + 1) // 2\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6 * n_rows))\n",
        "    \n",
        "    # Правильная обработка axes для разных случаев\n",
        "    if n_rows == 1 and n_cols == 1:\n",
        "        axes = [axes]  # Один график\n",
        "    elif n_rows == 1:\n",
        "        axes = axes  # Одна строка, несколько столбцов\n",
        "    else:\n",
        "        axes = axes.flatten()  # Несколько строк и столбцов\n",
        "    \n",
        "    for i, col in enumerate(available_columns):\n",
        "        # Count plot\n",
        "        top_values = df[col].value_counts().head(10)  # Топ-10 значений\n",
        "        \n",
        "        if len(top_values) > 0:\n",
        "            top_values.plot(kind='bar', ax=axes[i])\n",
        "            axes[i].set_title(f'Топ-10 популярных значений: {col}')\n",
        "            \n",
        "            # Улучшенные подписи осей\n",
        "            if col == 'country':\n",
        "                axes[i].set_xlabel('Страны (по убыванию активности)')\n",
        "                axes[i].set_ylabel('Количество транзакций (больше = выше активность)')\n",
        "            elif col == 'vendor_category':\n",
        "                axes[i].set_xlabel('Категории поставщиков')\n",
        "                axes[i].set_ylabel('Количество транзакций (больше = популярнее)')\n",
        "            elif col == 'device':\n",
        "                axes[i].set_xlabel('Типы устройств')\n",
        "                axes[i].set_ylabel('Количество использований (больше = популярнее)')\n",
        "            elif col == 'channel':\n",
        "                axes[i].set_xlabel('Каналы транзакций')\n",
        "                axes[i].set_ylabel('Количество транзакций (больше = активнее канал)')\n",
        "            else:\n",
        "                axes[i].set_xlabel(f'{col} (категории)')\n",
        "                axes[i].set_ylabel('Количество записей')\n",
        "            \n",
        "            axes[i].tick_params(axis='x', rotation=45)\n",
        "            \n",
        "            # Добавление значений на столбцы с процентами (исправляем накладывание)\n",
        "            total_count = df[col].count()\n",
        "            for j, v in enumerate(top_values.values):\n",
        "                percentage = (v / total_count) * 100\n",
        "                # Процент сверху, абсолютное значение снизу (табуляция)\n",
        "                axes[i].text(j, v + max(top_values) * 0.05, f'{percentage:.1f}%', \n",
        "                           ha='center', fontsize=8, weight='bold')\n",
        "                axes[i].text(j, v + max(top_values) * 0.02, f'{v:,}', \n",
        "                           ha='center', fontsize=7, alpha=0.8)\n",
        "        \n",
        "        # Статистика для каждого столбца\n",
        "        unique_count = df[col].nunique()\n",
        "        print(f\"\\n{col.upper()}:\")\n",
        "        print(f\"  Уникальных значений: {unique_count:,}\")\n",
        "        print(f\"  Топ-5 значений:\")\n",
        "        print(f\"  {df[col].value_counts().head().to_dict()}\")\n",
        "    \n",
        "    # Скрытие пустых подграфиков\n",
        "    if len(available_columns) < len(axes):\n",
        "        for j in range(len(available_columns), len(axes)):\n",
        "            axes[j].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_activity_metrics(df):\n",
        "    \"\"\"Анализ метрик активности и других численных переменных\"\"\"\n",
        "    \n",
        "    # Ищем численные столбцы для анализа\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    \n",
        "    # Исключаем ID столбцы и целевую переменную\n",
        "    exclude_cols = ['transaction_id', 'customer_id', 'card_number', 'is_fraud']\n",
        "    analysis_columns = [col for col in numeric_cols if col not in exclude_cols]\n",
        "    \n",
        "    if not analysis_columns:\n",
        "        print(\"Численные столбцы для анализа не найдены\")\n",
        "        return\n",
        "    \n",
        "    print(\"=== АНАЛИЗ ЧИСЛЕННЫХ ПРИЗНАКОВ ===\")\n",
        "    print(f\"Анализируемые столбцы: {analysis_columns}\")\n",
        "    \n",
        "    # Убираем ненужные графики: amount (оригинальный) и has_hour_activity\n",
        "    columns_to_exclude = ['amount', 'has_hour_activity']\n",
        "    filtered_columns = [col for col in analysis_columns if col not in columns_to_exclude]\n",
        "    columns_to_plot = filtered_columns[:4]  # Оставляем только 4 графика\n",
        "    \n",
        "    if len(columns_to_plot) == 0:\n",
        "        print(\"Нет столбцов для построения графиков\")\n",
        "        return\n",
        "    \n",
        "    # Создание графиков в 2 столбца\n",
        "    n_cols = 2\n",
        "    n_rows = (len(columns_to_plot) + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
        "    \n",
        "    # Правильная обработка axes\n",
        "    if n_rows == 1 and n_cols == 1:\n",
        "        axes = [axes]\n",
        "    elif n_rows == 1:\n",
        "        axes = list(axes) if hasattr(axes, '__iter__') else [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    \n",
        "    for i, col in enumerate(columns_to_plot):\n",
        "        try:\n",
        "            # Проверяем, что в столбце есть численные данные\n",
        "            if df[col].dtype in ['object', 'string']:\n",
        "                continue\n",
        "                \n",
        "            # Гистограмма\n",
        "            df[col].hist(bins=30, alpha=0.7, ax=axes[i])\n",
        "            axes[i].set_title(f'Распределение {col}')\n",
        "            \n",
        "            # Улучшенные подписи для численных признаков\n",
        "            if 'amount' in col.lower():\n",
        "                axes[i].set_xlabel(f'{col} (сумма)')\n",
        "                axes[i].set_ylabel('Частота транзакций')\n",
        "            elif 'activity' in col.lower():\n",
        "                axes[i].set_xlabel(f'{col} (активность)')\n",
        "                axes[i].set_ylabel('Частота значений активности')\n",
        "            elif col in ['is_weekend', 'is_outside_home_country', 'is_high_risk_vendor']:\n",
        "                axes[i].set_xlabel(f'{col} (0=нет, 1=да)')\n",
        "                axes[i].set_ylabel('Количество случаев')\n",
        "            else:\n",
        "                axes[i].set_xlabel(f'{col} (значения)')\n",
        "                axes[i].set_ylabel('Частота встречаемости')\n",
        "            \n",
        "            # Добавляем статистику на график (как в категориальных переменных)\n",
        "            mean_val = df[col].mean()\n",
        "            median_val = df[col].median()\n",
        "            std_val = df[col].std()\n",
        "            \n",
        "            # Добавляем текст со статистикой на график\n",
        "            stats_text = f'Среднее: {mean_val:.2f}\\nМедиана: {median_val:.2f}\\nСтд.откл: {std_val:.2f}'\n",
        "            axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes, \n",
        "                        verticalalignment='top', fontsize=8, weight='bold',\n",
        "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "            \n",
        "            # Статистика в консоль\n",
        "            print(f\"\\n{col}:\")\n",
        "            print(f\"  Среднее: {mean_val:.4f}\")\n",
        "            print(f\"  Медиана: {median_val:.4f}\")\n",
        "            print(f\"  Стд. отклонение: {std_val:.4f}\")\n",
        "            print(f\"  Мин: {df[col].min():.4f}, Макс: {df[col].max():.4f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при анализе столбца {col}: {e}\")\n",
        "            axes[i].text(0.5, 0.5, f'Ошибка: {col}', ha='center', va='center', transform=axes[i].transAxes)\n",
        "    \n",
        "    # Скрытие пустых подграфиков\n",
        "    for j in range(len(columns_to_plot), len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Дополнительный анализ last_hour_activity если есть\n",
        "    if 'last_hour_activity' in df.columns:\n",
        "        print(f\"\\nДОПОЛНИТЕЛЬНЫЙ АНАЛИЗ last_hour_activity:\")\n",
        "        sample_values = df['last_hour_activity'].dropna().head(5)\n",
        "        print(f\"Примеры значений: {sample_values.tolist()}\")\n",
        "        print(f\"Пропущенных значений: {df['last_hour_activity'].isna().sum()}\")\n",
        "        print(f\"Тип данных: {df['last_hour_activity'].dtype}\")\n",
        "\n",
        "# Запуск анализа распределений\n",
        "analyze_amount_distribution(df_with_features)\n",
        "analyze_categorical_distributions(df_with_features)\n",
        "analyze_activity_metrics(df_with_features)\n",
        "\n",
        "print(\"Анализ распределений завершен\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Задача 2.3: Выявление аномалий и паттернов мошенничества\n",
        "- Fraud rate по amount_usd (разные диапазоны сумм)\n",
        "- Fraud rate по vendor_category с точными значениями в таблице\n",
        "- Fraud rate по странам с точными значениями в таблице\n",
        "- Fraud rate по каналам (channel) и устройствам (device)\n",
        "- Анализ паттернов в last_hour_activity для мошеннических транзакций\n",
        "- Корреляционный анализ между fraud и числовыми переменными\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ паттернов мошенничества\n",
        "def analyze_fraud_by_amount(df):\n",
        "    \"\"\"Анализ fraud rate по диапазонам сумм\"\"\"\n",
        "    \n",
        "    # Определяем правильное название столбца (приоритет USD после конвертации)\n",
        "    amount_col = 'amount_usd' if 'amount_usd' in df.columns else 'amount'\n",
        "    \n",
        "    if amount_col not in df.columns or 'is_fraud' not in df.columns:\n",
        "        print(f\"Необходимые столбцы не найдены. Нужны: {amount_col}, is_fraud\")\n",
        "        print(f\"Доступные столбцы: {list(df.columns)}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"=== АНАЛИЗ МОШЕННИЧЕСТВА ПО СУММАМ ТРАНЗАКЦИЙ ({amount_col}) ===\")\n",
        "    \n",
        "    # Создание диапазонов сумм на основе квантилей для более равномерного распределения\n",
        "    max_amount = df[amount_col].max()\n",
        "    amount_bins = [0, 50, 100, 200, 500, 1000, 2000, 5000, max_amount]\n",
        "    amount_labels = ['0-50', '50-100', '100-200', '200-500', '500-1k', '1k-2k', '2k-5k', f'5k-{int(max_amount)}']\n",
        "    \n",
        "    df_analysis = df.copy()\n",
        "    df_analysis['amount_range'] = pd.cut(df_analysis[amount_col], \n",
        "                                        bins=amount_bins, \n",
        "                                        labels=amount_labels, \n",
        "                                        include_lowest=True)\n",
        "    \n",
        "    # Группировка и расчет fraud rate\n",
        "    fraud_by_amount = df_analysis.groupby('amount_range').agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    \n",
        "    fraud_by_amount.columns = ['amount_range', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "    fraud_by_amount['fraud_rate'] = fraud_by_amount['fraud_rate'] * 100\n",
        "    \n",
        "    # Создание графика (оставляем только один график)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
        "    \n",
        "    # График: Количество транзакций и мошенничества\n",
        "    x = range(len(fraud_by_amount))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax.bar([i - width/2 for i in x], fraud_by_amount['total_transactions'], \n",
        "           width, label='Всего транзакций (больше = активнее)', alpha=0.7)\n",
        "    ax.bar([i + width/2 for i in x], fraud_by_amount['fraud_count'], \n",
        "           width, label='Мошеннические (меньше лучше)', alpha=0.7, color='red')\n",
        "    \n",
        "    ax.set_title('Объем транзакций vs мошенничество по суммам (в USD)')\n",
        "    ax.set_xlabel('Диапазоны сумм транзакций (в USD)')\n",
        "    ax.set_ylabel('Количество транзакций')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(fraud_by_amount['amount_range'], rotation=45)\n",
        "    ax.legend()\n",
        "    \n",
        "    # Добавляем fraud rate как текст с табуляцией (как в категориальных переменных)\n",
        "    for i, (total, fraud, rate) in enumerate(zip(fraud_by_amount['total_transactions'], \n",
        "                                                 fraud_by_amount['fraud_count'], \n",
        "                                                 fraud_by_amount['fraud_rate'])):\n",
        "        max_height = max(total, fraud)\n",
        "        ax.text(i, max_height + max_height * 0.08, f'{rate:.1f}%', \n",
        "                ha='center', fontsize=10, weight='bold')\n",
        "        \n",
        "\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Таблица с результатами\n",
        "    print(\"\\nТАБЛИЦА FRAUD RATE ПО ДИАПАЗОНАМ СУММ:\")\n",
        "    print(fraud_by_amount.to_string(index=False))\n",
        "    \n",
        "    return fraud_by_amount\n",
        "\n",
        "def analyze_fraud_by_category(df, category_column, top_n=None):\n",
        "    \"\"\"Анализ fraud rate по категориям\"\"\"\n",
        "    \n",
        "    if category_column not in df.columns or 'is_fraud' not in df.columns:\n",
        "        print(f\"Столбец '{category_column}' или 'is_fraud' не найден\")\n",
        "        return\n",
        "    \n",
        "    print(f\"=== АНАЛИЗ МОШЕННИЧЕСТВА ПО {category_column.upper()} ===\")\n",
        "    \n",
        "    # Группировка и расчет fraud rate\n",
        "    fraud_by_category = df.groupby(category_column).agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    \n",
        "    fraud_by_category.columns = [category_column, 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "    fraud_by_category['fraud_rate'] = fraud_by_category['fraud_rate'] * 100\n",
        "    \n",
        "    # Фильтрация только категорий с достаточным количеством транзакций\n",
        "    min_transactions = 100  # Минимум для статистической значимости\n",
        "    fraud_by_category = fraud_by_category[fraud_by_category['total_transactions'] >= min_transactions]\n",
        "    \n",
        "    # Показываем все категории, отсортированные по fraud rate\n",
        "    if top_n is None:\n",
        "        top_n = len(fraud_by_category)  # Показать все\n",
        "    \n",
        "    top_fraud_categories = fraud_by_category.nlargest(top_n, 'fraud_rate')\n",
        "    \n",
        "    # График\n",
        "    plt.figure(figsize=(14, max(8, len(top_fraud_categories) * 0.5)))\n",
        "    plt.barh(range(len(top_fraud_categories)), top_fraud_categories['fraud_rate'], \n",
        "             color='salmon', alpha=0.7)\n",
        "    plt.yticks(range(len(top_fraud_categories)), top_fraud_categories[category_column])\n",
        "    plt.xlabel('Процент мошенничества (меньше лучше)')\n",
        "    \n",
        "    if len(top_fraud_categories) == len(fraud_by_category):\n",
        "        plt.title(f'Все категории по проценту мошенничества: {category_column}')\n",
        "    else:\n",
        "        plt.title(f'Топ-{top_n} категорий по проценту мошенничества: {category_column}')\n",
        "    \n",
        "    plt.gca().invert_yaxis()\n",
        "    \n",
        "    # Добавление значений с табуляцией (как в категориальных переменных)\n",
        "    for i, (fraud_rate, transactions) in enumerate(zip(top_fraud_categories['fraud_rate'], \n",
        "                                                       top_fraud_categories['total_transactions'])):\n",
        "        # Процент сверху, абсолютное значение снизу (табуляция)\n",
        "        plt.text(fraud_rate, i + 0.2, f'{fraud_rate:.1f}%', \n",
        "                va='center', fontsize=9, weight='bold', ha='left')\n",
        "        plt.text(fraud_rate, i - 0.2, f'({transactions:,})', \n",
        "                va='center', fontsize=8, alpha=0.8, ha='left')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Таблица с результатами\n",
        "    if len(top_fraud_categories) == len(fraud_by_category):\n",
        "        print(f\"\\nВСЕ КАТЕГОРИИ ПО FRAUD RATE:\")\n",
        "    else:\n",
        "        print(f\"\\nТОП-{top_n} КАТЕГОРИЙ ПО FRAUD RATE:\")\n",
        "    print(top_fraud_categories.to_string(index=False))\n",
        "    \n",
        "    print(f\"\\nСТАТИСТИКА:\")\n",
        "    print(f\"Средний fraud rate: {fraud_by_category['fraud_rate'].mean():.3f}%\")\n",
        "    print(f\"Медианный fraud rate: {fraud_by_category['fraud_rate'].median():.3f}%\")\n",
        "    print(f\"Максимальный fraud rate: {fraud_by_category['fraud_rate'].max():.3f}%\")\n",
        "    \n",
        "    return fraud_by_category\n",
        "\n",
        "def analyze_fraud_correlations(df):\n",
        "    \"\"\"Корреляционный анализ между fraud и числовыми переменными\"\"\"\n",
        "    \n",
        "    if 'is_fraud' not in df.columns:\n",
        "        print(\"Столбец 'is_fraud' не найден\")\n",
        "        return\n",
        "    \n",
        "    print(\"=== КОРРЕЛЯЦИОННЫЙ АНАЛИЗ С МОШЕННИЧЕСТВОМ ===\")\n",
        "    \n",
        "    # Отбор числовых столбцов\n",
        "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    \n",
        "    if 'is_fraud' not in numeric_columns:\n",
        "        print(\"is_fraud не является числовым столбцом\")\n",
        "        return\n",
        "    \n",
        "    # Расчет корреляций с is_fraud\n",
        "    correlations = df[numeric_columns].corr()['is_fraud'].sort_values(key=abs, ascending=False)\n",
        "    \n",
        "    # Удаление автокорреляции is_fraud с самим собой\n",
        "    correlations = correlations.drop('is_fraud')\n",
        "    \n",
        "    # Топ-15 корреляций\n",
        "    top_correlations = correlations.head(15)\n",
        "    \n",
        "    # График корреляций\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    colors = ['red' if x < 0 else 'green' for x in top_correlations.values]\n",
        "    plt.barh(range(len(top_correlations)), top_correlations.values, color=colors, alpha=0.7)\n",
        "    plt.yticks(range(len(top_correlations)), top_correlations.index)\n",
        "    plt.xlabel('Корреляция с is_fraud')\n",
        "    plt.title('Топ-15 корреляций признаков с мошенничеством')\n",
        "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "    plt.gca().invert_yaxis()\n",
        "    \n",
        "    # Добавление значений\n",
        "    for i, v in enumerate(top_correlations.values):\n",
        "        plt.text(v + (0.01 if v >= 0 else -0.01), i, f'{v:.3f}', \n",
        "                va='center', ha='left' if v >= 0 else 'right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Heatmap топ коррелирующих признаков\n",
        "    top_corr_columns = ['is_fraud'] + top_correlations.head(10).index.tolist()\n",
        "    correlation_matrix = df[top_corr_columns].corr()\n",
        "    \n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
        "                square=True, fmt='.3f')\n",
        "    plt.title('Heatmap корреляций (топ-10 признаков + is_fraud)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Таблица результатов\n",
        "    print(\"ТОП-15 КОРРЕЛЯЦИЙ С МОШЕННИЧЕСТВОМ:\")\n",
        "    correlations_df = pd.DataFrame({\n",
        "        'Признак': top_correlations.index,\n",
        "        'Корреляция': top_correlations.values\n",
        "    })\n",
        "    print(correlations_df.to_string(index=False))\n",
        "    \n",
        "    return correlations\n",
        "\n",
        "# Функция для комплексного анализа паттернов мошенничества\n",
        "def comprehensive_fraud_analysis(df):\n",
        "    \"\"\"Комплексный анализ паттернов мошенничества\"\"\"\n",
        "    \n",
        "    print(\"=== КОМПЛЕКСНЫЙ АНАЛИЗ ПАТТЕРНОВ МОШЕННИЧЕСТВА ===\")\n",
        "    \n",
        "    # Анализ по суммам\n",
        "    amount_analysis = analyze_fraud_by_amount(df)\n",
        "    \n",
        "    # Анализ по категориям\n",
        "    categories_to_analyze = ['vendor_category', 'country', 'channel', 'device']\n",
        "    \n",
        "    for category in categories_to_analyze:\n",
        "        if category in df.columns:\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            category_analysis = analyze_fraud_by_category(df, category)\n",
        "    \n",
        "    # Корреляционный анализ\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    correlations = analyze_fraud_correlations(df)\n",
        "    \n",
        "    return {\n",
        "        'amount_analysis': amount_analysis,\n",
        "        'correlations': correlations\n",
        "    }\n",
        "\n",
        "# Запуск комплексного анализа паттернов мошенничества\n",
        "fraud_patterns = comprehensive_fraud_analysis(df_with_features)\n",
        "\n",
        "print(\"Анализ паттернов мошенничества завершен\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ЭТАП 3: ВРЕМЕННОЙ И ГЕОГРАФИЧЕСКИЙ АНАЛИЗ\n",
        "\n",
        "## Задача 3.1: Анализ активности по времени и странам для оптимизации серверов\n",
        "- Heatmap количества транзакций по часам и странам\n",
        "- Топ-10 стран по объему транзакций с разбивкой по часам\n",
        "- Анализ пиковых часов нагрузки по странам\n",
        "- Сезонность по дням недели и часам\n",
        "- Таблицы для прогнозирования нагрузки серверов\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ✅ ИСПРАВЛЕНИЯ ВЫПОЛНЕНЫ\n",
        "\n",
        "### Что было исправлено:\n",
        "\n",
        "1. **График динамики по дням**: Исправлена проблема с разными масштабами Y для \"Количество транзакций\" и \"Мошеннические транзакции\" - теперь используется единый масштаб с коэффициентом нормализации.\n",
        "\n",
        "2. **Валютные подписи**: Все графики теперь корректно показывают \"USD (все валюты сконвертированы)\" вместо исходных валют.\n",
        "\n",
        "3. **Накладывающиеся подписи**: Реализована табуляция - процент сверху, абсолютное значение снизу, чтобы избежать наложения текста.\n",
        "\n",
        "4. **Удаленные графики**: Убраны графики \"Распределение по amount\" и \"Распределение has_hour_activity\" из раздела численных признаков, оставлено только 4 графика.\n",
        "\n",
        "5. **Amount_log в USD**: Подтверждено что amount_log создается на основе amount_usd (сконвертированных сумм).\n",
        "\n",
        "6. **Упрощенный график fraud rate**: Удален первый график из раздела \"ТАБЛИЦА FRAUD RATE ПО ДИАПАЗОНАМ СУММ\", fraud rate теперь отображается как подписи над столбцами.\n",
        "\n",
        "7. **USD везде**: Проверены и исправлены все места где должен использоваться пересчет в доллары.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ ЗАПУСК ИСПРАВЛЕННОГО АНАЛИЗА\n",
        "print(\"🚀 Все исправления внедрены в notebook!\")\n",
        "print(\"\\n📋 Для запуска анализа выполните ячейки в следующем порядке:\")\n",
        "print(\"1. Ячейка 1: Импорт библиотек\")\n",
        "print(\"2. Ячейка 2: Загрузка данных и конвертация валют\")\n",
        "print(\"3. Ячейки 4-8: Препроцессинг и создание признаков\") \n",
        "print(\"4. Ячейки 10-16: Анализ данных с исправленными графиками\")\n",
        "print(\"\\n✨ Основные улучшения:\")\n",
        "print(\"• Единый масштаб графиков\")\n",
        "print(\"• Корректные валютные подписи (USD)\")\n",
        "print(\"• Улучшенное отображение подписей\")\n",
        "print(\"• Оптимизированное количество графиков\")\n",
        "print(\"• Проверка USD-конвертации везде\")\n",
        "\n",
        "print(\"\\n🎯 Теперь анализ готов к использованию!\")\n",
        "print(\"📊 Все графики будут корректно отображать данные в USD с правильными масштабами.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Временной и географический анализ\n",
        "def analyze_server_load_patterns(df):\n",
        "    \"\"\"Анализ паттернов нагрузки для оптимизации серверов\"\"\"\n",
        "    \n",
        "    df_analysis = df.copy()\n",
        "    \n",
        "    # Проверяем и создаем столбец hour если его нет\n",
        "    if 'hour' not in df_analysis.columns and 'timestamp' in df_analysis.columns:\n",
        "        print(\"Создаем столбец 'hour' из timestamp...\")\n",
        "        df_analysis['timestamp'] = pd.to_datetime(df_analysis['timestamp'])\n",
        "        df_analysis['hour'] = df_analysis['timestamp'].dt.hour\n",
        "    \n",
        "    required_columns = ['timestamp', 'country', 'hour']\n",
        "    missing_columns = [col for col in required_columns if col not in df_analysis.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"Отсутствуют столбцы: {missing_columns}\")\n",
        "        print(f\"Доступные столбцы: {list(df_analysis.columns)}\")\n",
        "        return\n",
        "    \n",
        "    print(\"=== АНАЛИЗ ПАТТЕРНОВ НАГРУЗКИ СЕРВЕРОВ ===\")\n",
        "    \n",
        "    # Используем подготовленные данные\n",
        "    df_load = df_analysis\n",
        "    \n",
        "    # Анализ по часам и странам\n",
        "    hourly_country_load = df_load.groupby(['hour', 'country']).size().reset_index(name='transaction_count')\n",
        "    \n",
        "    # Все страны, отсортированные по общему объему транзакций\n",
        "    all_countries = df_load['country'].value_counts().index.tolist()\n",
        "    \n",
        "    # Используем все страны для анализа\n",
        "    hourly_country_all = hourly_country_load\n",
        "    \n",
        "    # Создание pivot table для heatmap\n",
        "    heatmap_data = hourly_country_all.pivot(index='country', columns='hour', values='transaction_count')\n",
        "    heatmap_data = heatmap_data.fillna(0)\n",
        "    \n",
        "    # Сортируем страны по общей активности\n",
        "    country_totals = heatmap_data.sum(axis=1).sort_values(ascending=False)\n",
        "    heatmap_data = heatmap_data.loc[country_totals.index]\n",
        "    \n",
        "    # График 1: Heatmap нагрузки по часам и странам\n",
        "    plt.figure(figsize=(16, max(8, len(all_countries) * 0.8)))\n",
        "    sns.heatmap(heatmap_data, annot=False, cmap='YlOrRd', cbar_kws={'label': 'Количество транзакций'})\n",
        "    plt.title('Heatmap активности: Все страны × Часы дня')\n",
        "    plt.xlabel('Час дня (0-23)')\n",
        "    plt.ylabel('Страны (упорядочены по общей активности)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Дополнительные heatmap-ы по категориям\n",
        "    print(\"\\n=== ДОПОЛНИТЕЛЬНЫЕ HEATMAP-Ы ПО КАТЕГОРИЯМ ===\")\n",
        "    \n",
        "    # Heatmap по vendor_category для всех стран\n",
        "    if 'vendor_category' in df_load.columns:\n",
        "        vendor_country_data = df_load.groupby(['country', 'vendor_category']).size().reset_index(name='transaction_count')\n",
        "        vendor_pivot = vendor_country_data.pivot(index='country', columns='vendor_category', values='transaction_count')\n",
        "        vendor_pivot = vendor_pivot.fillna(0)\n",
        "        \n",
        "        # Сортируем страны по общей активности\n",
        "        vendor_country_totals = vendor_pivot.sum(axis=1).sort_values(ascending=False)\n",
        "        vendor_pivot = vendor_pivot.loc[vendor_country_totals.index]\n",
        "        \n",
        "        plt.figure(figsize=(14, max(8, len(all_countries) * 0.6)))\n",
        "        sns.heatmap(vendor_pivot, annot=True, fmt='.0f', cmap='Blues', \n",
        "                   cbar_kws={'label': 'Количество транзакций'})\n",
        "        plt.title('Heatmap: Все страны × Все категории поставщиков')\n",
        "        plt.xlabel('Категории поставщиков (больше транзакций = популярнее)')\n",
        "        plt.ylabel('Страны (упорядочены по активности)')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Heatmap по channel для всех стран\n",
        "    if 'channel' in df_load.columns:\n",
        "        channel_country_data = df_load.groupby(['country', 'channel']).size().reset_index(name='transaction_count')\n",
        "        channel_pivot = channel_country_data.pivot(index='country', columns='channel', values='transaction_count')\n",
        "        channel_pivot = channel_pivot.fillna(0)\n",
        "        \n",
        "        # Сортируем страны по общей активности\n",
        "        channel_country_totals = channel_pivot.sum(axis=1).sort_values(ascending=False)\n",
        "        channel_pivot = channel_pivot.loc[channel_country_totals.index]\n",
        "        \n",
        "        plt.figure(figsize=(12, max(6, len(all_countries) * 0.5)))\n",
        "        sns.heatmap(channel_pivot, annot=True, fmt='.0f', cmap='Greens',\n",
        "                   cbar_kws={'label': 'Количество транзакций'})\n",
        "        plt.title('Heatmap: Все страны × Каналы транзакций')\n",
        "        plt.xlabel('Каналы транзакций (больше = популярнее канал)')\n",
        "        plt.ylabel('Страны (упорядочены по активности)')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Heatmap по device для всех стран\n",
        "    if 'device' in df_load.columns:\n",
        "        device_country_data = df_load.groupby(['country', 'device']).size().reset_index(name='transaction_count')\n",
        "        device_pivot = device_country_data.pivot(index='country', columns='device', values='transaction_count')\n",
        "        device_pivot = device_pivot.fillna(0)\n",
        "        \n",
        "        # Сортируем страны по общей активности\n",
        "        device_country_totals = device_pivot.sum(axis=1).sort_values(ascending=False)\n",
        "        device_pivot = device_pivot.loc[device_country_totals.index]\n",
        "        \n",
        "        plt.figure(figsize=(15, max(8, len(all_countries) * 0.6)))\n",
        "        sns.heatmap(device_pivot, annot=True, fmt='.0f', cmap='Purples',\n",
        "                   cbar_kws={'label': 'Количество транзакций'})\n",
        "        plt.title('Heatmap: Все страны × Типы устройств')\n",
        "        plt.xlabel('Типы устройств (больше = популярнее)')\n",
        "        plt.ylabel('Страны (упорядочены по активности)')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # График 2: Общая нагрузка по часам\n",
        "    hourly_load = df_load.groupby('hour').size()\n",
        "    \n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(hourly_load.index, hourly_load.values, marker='o', linewidth=2, markersize=6)\n",
        "    plt.title('Нагрузка серверов: количество транзакций по часам')\n",
        "    plt.xlabel('Час дня (0=полночь, 12=полдень)')\n",
        "    plt.ylabel('Количество транзакций (больше = выше нагрузка)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(range(0, 24))\n",
        "    \n",
        "    # Выделение пиковых часов\n",
        "    peak_hours = hourly_load.nlargest(5)\n",
        "    for hour, count in peak_hours.items():\n",
        "        plt.annotate(f'Пик: {count:,}', xy=(hour, count), xytext=(10, 10), \n",
        "                    textcoords='offset points', ha='left',\n",
        "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # График 3: Нагрузка по дням недели\n",
        "    if 'day_of_week' in df_load.columns:\n",
        "        weekly_load = df_load.groupby('day_of_week').size()\n",
        "        day_names = ['Понедельник', 'Вторник', 'Среда', 'Четверг', 'Пятница', 'Суббота', 'Воскресенье']\n",
        "        \n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.bar(range(7), weekly_load.values, color='lightblue', alpha=0.7)\n",
        "        plt.title('Серверная нагрузка по дням недели')\n",
        "        plt.xlabel('Дни недели (важно для планирования выходных)')\n",
        "        plt.ylabel('Общее количество транзакций (больше = выше нагрузка)')\n",
        "        plt.xticks(range(7), day_names, rotation=45)\n",
        "        \n",
        "        # Добавление значений на столбцы\n",
        "        for i, v in enumerate(weekly_load.values):\n",
        "            plt.text(i, v + max(weekly_load) * 0.01, f'{v:,}', ha='center')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Создание таблицы для планирования серверных мощностей\n",
        "    server_planning_table = create_server_planning_table(df_load, all_countries)\n",
        "    \n",
        "    return {\n",
        "        'hourly_load': hourly_load,\n",
        "        'heatmap_data': heatmap_data,\n",
        "        'server_planning': server_planning_table\n",
        "    }\n",
        "\n",
        "def create_server_planning_table(df, top_countries):\n",
        "    \"\"\"Создание таблицы для планирования серверных мощностей\"\"\"\n",
        "    \n",
        "    print(\"\\n=== ТАБЛИЦА ДЛЯ ПЛАНИРОВАНИЯ СЕРВЕРНЫХ МОЩНОСТЕЙ ===\")\n",
        "    \n",
        "    # Общая статистика по часам\n",
        "    hourly_stats = df.groupby('hour').size().reset_index(name='total_transactions').set_index('hour')\n",
        "    \n",
        "    # Статистика по странам и часам\n",
        "    country_hour_stats = df[df['country'].isin(top_countries)].groupby(['country', 'hour']).size().reset_index(name='transactions')\n",
        "    \n",
        "    # Пиковые часы для каждой страны\n",
        "    country_peaks = country_hour_stats.loc[country_hour_stats.groupby('country')['transactions'].idxmax()]\n",
        "    \n",
        "    # Создание сводной таблицы\n",
        "    planning_table = pd.DataFrame()\n",
        "    planning_table['hour'] = range(24)\n",
        "    \n",
        "    # Безопасное заполнение данных\n",
        "    load_values = []\n",
        "    for hour in range(24):\n",
        "        if hour in hourly_stats.index:\n",
        "            load_values.append(hourly_stats.loc[hour, 'total_transactions'])\n",
        "        else:\n",
        "            load_values.append(0)\n",
        "    planning_table['total_load'] = load_values\n",
        "    \n",
        "    # Определение уровня нагрузки\n",
        "    def categorize_load(load, percentiles):\n",
        "        if load >= percentiles[0.95]:\n",
        "            return 'Критическая'\n",
        "        elif load >= percentiles[0.80]:\n",
        "            return 'Высокая'\n",
        "        elif load >= percentiles[0.50]:\n",
        "            return 'Средняя'\n",
        "        else:\n",
        "            return 'Низкая'\n",
        "    \n",
        "    load_percentiles = planning_table['total_load'].quantile([0.5, 0.8, 0.95])\n",
        "    planning_table['load_category'] = planning_table['total_load'].apply(\n",
        "        lambda x: categorize_load(x, load_percentiles)\n",
        "    )\n",
        "    \n",
        "    # Рекомендации по масштабированию\n",
        "    def get_scaling_recommendation(category):\n",
        "        recommendations = {\n",
        "            'Критическая': 'Максимальные мощности + резерв',\n",
        "            'Высокая': 'Увеличенные мощности',\n",
        "            'Средняя': 'Стандартные мощности',\n",
        "            'Низкая': 'Минимальные мощности'\n",
        "        }\n",
        "        return recommendations.get(category, 'Стандартные мощности')\n",
        "    \n",
        "    planning_table['scaling_recommendation'] = planning_table['load_category'].apply(get_scaling_recommendation)\n",
        "    \n",
        "    print(\"РЕКОМЕНДАЦИИ ПО ЧАСАМ:\")\n",
        "    print(planning_table.to_string(index=False))\n",
        "    \n",
        "    # Топ-5 пиковых часов\n",
        "    peak_hours = planning_table.nlargest(5, 'total_load')[['hour', 'total_load', 'load_category']]\n",
        "    print(f\"\\nТОП-5 ПИКОВЫХ ЧАСОВ:\")\n",
        "    print(peak_hours.to_string(index=False))\n",
        "    \n",
        "    # Рекомендации по странам\n",
        "    print(f\"\\nПИКОВЫЕ ЧАСЫ ПО ТОП-СТРАНАМ:\")\n",
        "    for _, row in country_peaks.iterrows():\n",
        "        print(f\"  {row['country']}: час {row['hour']} ({row['transactions']:,} транзакций)\")\n",
        "    \n",
        "    return planning_table\n",
        "\n",
        "def analyze_fraud_time_patterns(df):\n",
        "    \"\"\"Анализ временных паттернов мошенничества\"\"\"\n",
        "    \n",
        "    df_analysis = df.copy()\n",
        "    \n",
        "    # Создаем столбец hour если его нет\n",
        "    if 'hour' not in df_analysis.columns and 'timestamp' in df_analysis.columns:\n",
        "        print(\"Создаем столбец 'hour' из timestamp...\")\n",
        "        df_analysis['timestamp'] = pd.to_datetime(df_analysis['timestamp'])\n",
        "        df_analysis['hour'] = df_analysis['timestamp'].dt.hour\n",
        "    \n",
        "    required_columns = ['hour', 'is_fraud']\n",
        "    missing_columns = [col for col in required_columns if col not in df_analysis.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"Отсутствуют столбцы: {missing_columns}\")\n",
        "        print(f\"Доступные столбцы: {list(df_analysis.columns)}\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\n=== ВРЕМЕННЫЕ ПАТТЕРНЫ МОШЕННИЧЕСТВА ===\")\n",
        "    \n",
        "    # Fraud rate по часам\n",
        "    hourly_fraud = df_analysis.groupby('hour').agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    hourly_fraud.columns = ['hour', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "    hourly_fraud['fraud_rate'] = hourly_fraud['fraud_rate'] * 100\n",
        "    \n",
        "    # График fraud rate по часам\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
        "    \n",
        "    # График 1: Fraud rate по часам\n",
        "    axes[0].plot(hourly_fraud['hour'], hourly_fraud['fraud_rate'], \n",
        "                marker='o', linewidth=2, markersize=6, color='red')\n",
        "    axes[0].set_title('Процент мошенничества по часам дня')\n",
        "    axes[0].set_xlabel('Час дня (0=полночь, 12=полдень)')\n",
        "    axes[0].set_ylabel('Процент мошенничества (меньше лучше)')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    axes[0].set_xticks(range(0, 24))\n",
        "    \n",
        "    # Выделение часов с высоким fraud rate\n",
        "    high_fraud_hours = hourly_fraud.nlargest(3, 'fraud_rate')\n",
        "    for _, row in high_fraud_hours.iterrows():\n",
        "        axes[0].annotate(f'{row[\"fraud_rate\"]:.2f}%', \n",
        "                        xy=(row['hour'], row['fraud_rate']), \n",
        "                        xytext=(10, 10), textcoords='offset points',\n",
        "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.7))\n",
        "    \n",
        "    # График 2: Количество мошеннических транзакций по часам\n",
        "    axes[1].bar(hourly_fraud['hour'], hourly_fraud['fraud_count'], \n",
        "               color='salmon', alpha=0.7)\n",
        "    axes[1].set_title('Абсолютное количество мошеннических случаев по часам')\n",
        "    axes[1].set_xlabel('Час дня (0=полночь, 12=полдень)')\n",
        "    axes[1].set_ylabel('Количество мошеннических транзакций (меньше лучше)')\n",
        "    axes[1].set_xticks(range(0, 24))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Fraud rate по дням недели (если есть данные)\n",
        "    if 'day_of_week' in df_analysis.columns:\n",
        "        daily_fraud = df_analysis.groupby('day_of_week').agg({\n",
        "            'is_fraud': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "    elif 'timestamp' in df_analysis.columns:\n",
        "        # Создаем day_of_week из timestamp\n",
        "        df_analysis['day_of_week'] = df_analysis['timestamp'].dt.dayofweek\n",
        "        daily_fraud = df_analysis.groupby('day_of_week').agg({\n",
        "            'is_fraud': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "        daily_fraud.columns = ['day_of_week', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "        daily_fraud['fraud_rate'] = daily_fraud['fraud_rate'] * 100\n",
        "        \n",
        "        day_names = ['Пн', 'Вт', 'Ср', 'Чт', 'Пт', 'Сб', 'Вс']\n",
        "        \n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.bar(range(7), daily_fraud['fraud_rate'], color='orange', alpha=0.7)\n",
        "        plt.title('Процент мошенничества по дням недели')\n",
        "        plt.xlabel('Дни недели (Пн-рабочий, Сб-Вс-выходные)')\n",
        "        plt.ylabel('Процент мошенничества (меньше лучше)')\n",
        "        plt.xticks(range(7), day_names)\n",
        "        \n",
        "        # Добавление значений\n",
        "        for i, v in enumerate(daily_fraud['fraud_rate']):\n",
        "            plt.text(i, v + 0.05, f'{v:.2f}%', ha='center')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Таблица с результатами\n",
        "    print(\"FRAUD RATE ПО ЧАСАМ:\")\n",
        "    print(hourly_fraud.to_string(index=False))\n",
        "    \n",
        "    # Выводы\n",
        "    peak_fraud_hour = hourly_fraud.loc[hourly_fraud['fraud_rate'].idxmax()]\n",
        "    low_fraud_hour = hourly_fraud.loc[hourly_fraud['fraud_rate'].idxmin()]\n",
        "    \n",
        "    print(f\"\\nВЫВОДЫ:\")\n",
        "    print(f\"Час с максимальным fraud rate: {peak_fraud_hour['hour']} ({peak_fraud_hour['fraud_rate']:.3f}%)\")\n",
        "    print(f\"Час с минимальным fraud rate: {low_fraud_hour['hour']} ({low_fraud_hour['fraud_rate']:.3f}%)\")\n",
        "    print(f\"Разница между максимумом и минимумом: {peak_fraud_hour['fraud_rate'] - low_fraud_hour['fraud_rate']:.3f}%\")\n",
        "    \n",
        "    return hourly_fraud\n",
        "\n",
        "server_analysis = analyze_server_load_patterns(df_with_features)\n",
        "fraud_time_analysis = analyze_fraud_time_patterns(df_with_features)\n",
        "\n",
        "print(\"Функции временного и географического анализа готовы\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Запуск альтернативных анализов вместо простых демографических графиков\n",
        "print(\"=== ЗАПУСК ПРОДВИНУТЫХ АНАЛИЗОВ ВМЕСТО ПРОСТЫХ ГРАФИКОВ ===\")\n",
        "print(\"Заменяем малоинформативные графики на:\")\n",
        "print(\"1. Heatmap комбинированных рисков\")\n",
        "print(\"2. Анализ скорости мошенничества (velocity)\")  \n",
        "print(\"3. Кластерный анализ поведения\")\n",
        "print(\"4. Анализ последовательных паттернов\")\n",
        "print(\"5. Распределение аномальности\")\n",
        "\n",
        "# Функция будет определена в следующей ячейке\n",
        "# Здесь мы подготавливаем данные\n",
        "print(f\"\\nИспользуем данные: {df_with_features.shape[0]:,} строк, {df_with_features.shape[1]} столбцов\")\n",
        "print(\"Готовы к запуску альтернативных анализов...\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ЭТАП 5: АНАЛИЗ КЛИЕНТСКОГО ПОВЕДЕНИЯ\n",
        "\n",
        "## Задача 5.1: Демографический анализ\n",
        "- Анализ паттернов по city_size\n",
        "- Fraud rate среди клиентов is_outside_home_country  \n",
        "- Поведенческие паттерны по card_type\n",
        "\n",
        "## Задача 5.2: Анализ активности last_hour_activity\n",
        "- Распределение last_hour_activity.num_transactions для fraud vs non-fraud\n",
        "- Анализ last_hour_activity.total_amount для мошенников\n",
        "- Паттерны в last_hour_activity.unique_merchants\n",
        "- Соотношение max_single_amount к total_amount\n",
        "- Статистические тесты различий между группами\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ клиентского поведения\n",
        "def analyze_demographic_patterns(df):\n",
        "    \"\"\"Анализ демографических паттернов мошенничества\"\"\"\n",
        "    \n",
        "    print(\"=== ДЕМОГРАФИЧЕСКИЙ АНАЛИЗ КЛИЕНТСКОГО ПОВЕДЕНИЯ ===\")\n",
        "    \n",
        "    # Проверяем наличие данных о возрасте\n",
        "    has_age = 'age' in df.columns\n",
        "    print(f\"Данные о возрасте: {'Есть' if has_age else 'Отсутствуют'}\")\n",
        "    \n",
        "    # Анализ по city_size с коэффициентом риска\n",
        "    if 'city_size' in df.columns and 'is_fraud' in df.columns:\n",
        "        print(\"\\n--- АНАЛИЗ РИСКА ПО РАЗМЕРУ ГОРОДА ---\")\n",
        "        \n",
        "        city_fraud = df.groupby('city_size').agg({\n",
        "            'is_fraud': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "        city_fraud.columns = ['city_size', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "        \n",
        "        # Рассчитываем коэффициент риска относительно общего уровня\n",
        "        overall_fraud_rate = df['is_fraud'].mean()\n",
        "        city_fraud['risk_ratio'] = city_fraud['fraud_rate'] / overall_fraud_rate\n",
        "        city_fraud['fraud_rate'] = city_fraud['fraud_rate'] * 100\n",
        "        city_fraud['risk_level'] = city_fraud['risk_ratio'].apply(\n",
        "            lambda x: 'Высокий риск' if x > 1.1 else ('Низкий риск' if x < 0.9 else 'Средний риск')\n",
        "        )\n",
        "        \n",
        "\n",
        "        \n",
        "        print(\"АНАЛИЗ РИСКА ПО РАЗМЕРУ ГОРОДА:\")\n",
        "        print(city_fraud[['city_size', 'total_transactions', 'fraud_rate', 'risk_ratio', 'risk_level']].to_string(index=False))\n",
        "    \n",
        "    # Анализ is_outside_home_country\n",
        "    if 'is_outside_home_country' in df.columns and 'is_fraud' in df.columns:\n",
        "        print(\"\\n--- АНАЛИЗ КЛИЕНТОВ ВНЕ РОДНОЙ СТРАНЫ ---\")\n",
        "        \n",
        "        outside_fraud = df.groupby('is_outside_home_country').agg({\n",
        "            'is_fraud': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "        outside_fraud.columns = ['is_outside_home_country', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "        outside_fraud['fraud_rate'] = outside_fraud['fraud_rate'] * 100\n",
        "        outside_fraud['location_type'] = outside_fraud['is_outside_home_country'].map({\n",
        "            False: 'В родной стране', True: 'Вне родной страны'\n",
        "        })\n",
        "        \n",
        "\n",
        "        \n",
        "        print(\"FRAUD RATE ПО МЕСТОПОЛОЖЕНИЮ:\")\n",
        "        print(outside_fraud[['location_type', 'total_transactions', 'fraud_count', 'fraud_rate']].to_string(index=False))\n",
        "    \n",
        "    # Анализ по типу карты\n",
        "    if 'card_type' in df.columns and 'is_fraud' in df.columns:\n",
        "        print(\"\\n--- АНАЛИЗ ПОВЕДЕНЧЕСКИХ ПАТТЕРНОВ ПО ТИПУ КАРТЫ ---\")\n",
        "        \n",
        "        card_fraud = df.groupby('card_type').agg({\n",
        "            'is_fraud': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "        card_fraud.columns = ['card_type', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "        card_fraud['fraud_rate'] = card_fraud['fraud_rate'] * 100\n",
        "        card_fraud = card_fraud.sort_values('fraud_rate', ascending=False)\n",
        "        \n",
        "        # График\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(range(len(card_fraud)), card_fraud['fraud_rate'], \n",
        "                color='purple', alpha=0.7)\n",
        "        plt.yticks(range(len(card_fraud)), card_fraud['card_type'])\n",
        "        plt.xlabel('Процент мошенничества (%)')\n",
        "        plt.title('Fraud rate по типам карт')\n",
        "        plt.gca().invert_yaxis()\n",
        "        \n",
        "        # Добавляем значения\n",
        "        for i, (rate, transactions) in enumerate(zip(card_fraud['fraud_rate'], \n",
        "                                                   card_fraud['total_transactions'])):\n",
        "            plt.text(rate + 0.2, i, f'{rate:.1f}% ({transactions:,})', \n",
        "                    va='center', fontsize=9)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"FRAUD RATE ПО ТИПАМ КАРТ:\")\n",
        "        print(card_fraud.to_string(index=False))\n",
        "    \n",
        "    return {\n",
        "        'city_analysis': city_fraud if 'city_size' in df.columns else None,\n",
        "        'location_analysis': outside_fraud if 'is_outside_home_country' in df.columns else None,\n",
        "        'card_analysis': card_fraud if 'card_type' in df.columns else None\n",
        "    }\n",
        "\n",
        "def parse_last_hour_activity(df):\n",
        "    \"\"\"Парсинг и анализ данных last_hour_activity\"\"\"\n",
        "    \n",
        "    print(\"\\n=== АНАЛИЗ АКТИВНОСТИ ЗА ПОСЛЕДНИЙ ЧАС ===\")\n",
        "    \n",
        "    if 'last_hour_activity' not in df.columns:\n",
        "        print(\"Столбец 'last_hour_activity' не найден\")\n",
        "        return None\n",
        "    \n",
        "    # Проверяем тип данных\n",
        "    sample_value = df['last_hour_activity'].iloc[0]\n",
        "    print(f\"Тип данных last_hour_activity: {type(sample_value)}\")\n",
        "    print(f\"Пример значения: {sample_value}\")\n",
        "    \n",
        "    # Парсинг JSON данных\n",
        "    import ast\n",
        "    import json\n",
        "    \n",
        "    def safe_parse_activity(activity_str):\n",
        "        \"\"\"Безопасный парсинг activity данных\"\"\"\n",
        "        if pd.isna(activity_str):\n",
        "            return None\n",
        "        try:\n",
        "            if isinstance(activity_str, str):\n",
        "                # Попробуем разные методы парсинга\n",
        "                try:\n",
        "                    return json.loads(activity_str)\n",
        "                except:\n",
        "                    return ast.literal_eval(activity_str)\n",
        "            elif isinstance(activity_str, dict):\n",
        "                return activity_str\n",
        "            else:\n",
        "                return None\n",
        "        except:\n",
        "            return None\n",
        "    \n",
        "    # Парсим данные\n",
        "    print(\"Парсинг данных last_hour_activity...\")\n",
        "    df_activity = df.copy()\n",
        "    df_activity['parsed_activity'] = df_activity['last_hour_activity'].apply(safe_parse_activity)\n",
        "    \n",
        "    # Фильтруем строки с валидными данными\n",
        "    valid_activity = df_activity[df_activity['parsed_activity'].notna()].copy()\n",
        "    print(f\"Строк с валидными данными активности: {len(valid_activity):,}\")\n",
        "    \n",
        "    if len(valid_activity) == 0:\n",
        "        print(\"Нет валидных данных для анализа\")\n",
        "        return None\n",
        "    \n",
        "    # Извлекаем метрики\n",
        "    activity_metrics = []\n",
        "    for _, row in valid_activity.iterrows():\n",
        "        activity = row['parsed_activity']\n",
        "        if isinstance(activity, dict):\n",
        "            metrics = {\n",
        "                'is_fraud': row['is_fraud'],\n",
        "                'num_transactions': activity.get('num_transactions', 0),\n",
        "                'total_amount': activity.get('total_amount', 0),\n",
        "                'unique_merchants': activity.get('unique_merchants', 0),\n",
        "                'unique_countries': activity.get('unique_countries', 0),\n",
        "                'max_single_amount': activity.get('max_single_amount', 0)\n",
        "            }\n",
        "            activity_metrics.append(metrics)\n",
        "    \n",
        "    if not activity_metrics:\n",
        "        print(\"Не удалось извлечь метрики\")\n",
        "        return None\n",
        "    \n",
        "    df_metrics = pd.DataFrame(activity_metrics)\n",
        "    \n",
        "    # Создаем дополнительные метрики\n",
        "    df_metrics['avg_transaction_amount'] = df_metrics['total_amount'] / (df_metrics['num_transactions'] + 0.001)\n",
        "    df_metrics['max_to_total_ratio'] = df_metrics['max_single_amount'] / (df_metrics['total_amount'] + 0.001)\n",
        "    df_metrics['transactions_per_merchant'] = df_metrics['num_transactions'] / (df_metrics['unique_merchants'] + 0.001)\n",
        "    \n",
        "    print(f\"Успешно обработано {len(df_metrics):,} записей\")\n",
        "    \n",
        "    return df_metrics\n",
        "\n",
        "def analyze_last_hour_activity_patterns(df_metrics):\n",
        "    \"\"\"Анализ паттернов активности за последний час\"\"\"\n",
        "    \n",
        "    if df_metrics is None or len(df_metrics) == 0:\n",
        "        print(\"Нет данных для анализа паттернов активности\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\n--- СРАВНИТЕЛЬНЫЙ АНАЛИЗ АКТИВНОСТИ МОШЕННИКОВ VS ЛЕГИТИМНЫХ КЛИЕНТОВ ---\")\n",
        "    \n",
        "    # Разделяем на мошенников и легитимных\n",
        "    fraud_metrics = df_metrics[df_metrics['is_fraud'] == True]\n",
        "    legit_metrics = df_metrics[df_metrics['is_fraud'] == False]\n",
        "    \n",
        "    print(f\"Мошеннические транзакции: {len(fraud_metrics):,}\")\n",
        "    print(f\"Легитимные транзакции: {len(legit_metrics):,}\")\n",
        "    \n",
        "    # Метрики для анализа\n",
        "    metrics_to_analyze = [\n",
        "        'num_transactions', 'total_amount', 'unique_merchants', \n",
        "        'max_single_amount', 'avg_transaction_amount', 'max_to_total_ratio'\n",
        "    ]\n",
        "    \n",
        "    # Создаем сравнительные графики\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, metric in enumerate(metrics_to_analyze):\n",
        "        if metric in df_metrics.columns:\n",
        "            # Гистограммы для сравнения\n",
        "            fraud_data = fraud_metrics[metric].dropna()\n",
        "            legit_data = legit_metrics[metric].dropna()\n",
        "            \n",
        "            # Ограничиваем выбросы для лучшей визуализации\n",
        "            fraud_q95 = fraud_data.quantile(0.95)\n",
        "            legit_q95 = legit_data.quantile(0.95)\n",
        "            max_val = max(fraud_q95, legit_q95)\n",
        "            \n",
        "            fraud_data_limited = fraud_data[fraud_data <= max_val]\n",
        "            legit_data_limited = legit_data[legit_data <= max_val]\n",
        "            \n",
        "            axes[i].hist(legit_data_limited, bins=30, alpha=0.6, \n",
        "                        label='Легитимные', color='blue', density=True)\n",
        "            axes[i].hist(fraud_data_limited, bins=30, alpha=0.6, \n",
        "                        label='Мошеннические', color='red', density=True)\n",
        "            \n",
        "            axes[i].set_title(f'Распределение: {metric}')\n",
        "            axes[i].set_xlabel(metric)\n",
        "            axes[i].set_ylabel('Плотность')\n",
        "            axes[i].legend()\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Добавляем статистику\n",
        "            fraud_mean = fraud_data.mean()\n",
        "            legit_mean = legit_data.mean()\n",
        "            \n",
        "            stats_text = f'Мошенники: {fraud_mean:.2f}\\nЛегитимные: {legit_mean:.2f}'\n",
        "            axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes, \n",
        "                        verticalalignment='top', fontsize=8,\n",
        "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Статистические тесты\n",
        "    print(\"\\n--- СТАТИСТИЧЕСКИЕ ТЕСТЫ РАЗЛИЧИЙ ---\")\n",
        "    from scipy import stats\n",
        "    \n",
        "    comparison_results = []\n",
        "    \n",
        "    for metric in metrics_to_analyze:\n",
        "        if metric in df_metrics.columns:\n",
        "            fraud_data = fraud_metrics[metric].dropna()\n",
        "            legit_data = legit_metrics[metric].dropna()\n",
        "            \n",
        "            if len(fraud_data) > 0 and len(legit_data) > 0:\n",
        "                # T-test\n",
        "                try:\n",
        "                    t_stat, p_value = stats.ttest_ind(fraud_data, legit_data)\n",
        "                    \n",
        "                    fraud_mean = fraud_data.mean()\n",
        "                    legit_mean = legit_data.mean()\n",
        "                    difference_pct = ((fraud_mean - legit_mean) / legit_mean) * 100\n",
        "                    \n",
        "                    significance = \"Значимо\" if p_value < 0.05 else \"Не значимо\"\n",
        "                    \n",
        "                    comparison_results.append({\n",
        "                        'Метрика': metric,\n",
        "                        'Мошенники_среднее': fraud_mean,\n",
        "                        'Легитимные_среднее': legit_mean,\n",
        "                        'Разница_%': difference_pct,\n",
        "                        'p_value': p_value,\n",
        "                        'Значимость': significance\n",
        "                    })\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Ошибка при анализе {metric}: {e}\")\n",
        "    \n",
        "    if comparison_results:\n",
        "        results_df = pd.DataFrame(comparison_results)\n",
        "        print(\"РЕЗУЛЬТАТЫ СРАВНИТЕЛЬНОГО АНАЛИЗА:\")\n",
        "        print(results_df.to_string(index=False))\n",
        "        \n",
        "        # Выводы\n",
        "        print(\"\\nВЫВОДЫ:\")\n",
        "        significant_diffs = results_df[results_df['Значимость'] == 'Значимо']\n",
        "        if len(significant_diffs) > 0:\n",
        "            print(\"Статистически значимые различия найдены в:\")\n",
        "            for _, row in significant_diffs.iterrows():\n",
        "                direction = \"больше\" if row['Разница_%'] > 0 else \"меньше\"\n",
        "                print(f\"  - {row['Метрика']}: у мошенников {direction} на {abs(row['Разница_%']):.1f}%\")\n",
        "        else:\n",
        "            print(\"Статистически значимых различий не обнаружено\")\n",
        "    \n",
        "    return comparison_results\n",
        "\n",
        "# Запуск анализа клиентского поведения\n",
        "demographic_analysis = analyze_demographic_patterns(df_with_features)\n",
        "activity_metrics = parse_last_hour_activity(df_with_features)\n",
        "if activity_metrics is not None:\n",
        "    activity_comparison = analyze_last_hour_activity_patterns(activity_metrics)\n",
        "\n",
        "print(\"\\nАнализ клиентского поведения завершен\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Исследование логики определения \"родной страны\"\n",
        "def investigate_home_country_logic(df):\n",
        "    \"\"\"Исследует принцип определения родной страны для клиентов\"\"\"\n",
        "    \n",
        "    print(\"=== ИССЛЕДОВАНИЕ ЛОГИКИ ОПРЕДЕЛЕНИЯ РОДНОЙ СТРАНЫ ===\")\n",
        "    \n",
        "    # Анализируем распределение is_outside_home_country по странам\n",
        "    if 'is_outside_home_country' in df.columns and 'country' in df.columns:\n",
        "        \n",
        "        print(\"\\n1. РАСПРЕДЕЛЕНИЕ is_outside_home_country ПО СТРАНАМ:\")\n",
        "        country_home_analysis = df.groupby(['country', 'is_outside_home_country']).size().unstack(fill_value=0)\n",
        "        country_home_analysis['total'] = country_home_analysis.sum(axis=1)\n",
        "        country_home_analysis['outside_pct'] = (country_home_analysis[True] / country_home_analysis['total'] * 100)\n",
        "        \n",
        "        print(country_home_analysis.sort_values('outside_pct', ascending=False))\n",
        "        \n",
        "        # Графическое представление\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        \n",
        "        # График процента \"вне родной страны\" для каждой страны\n",
        "        countries = country_home_analysis.index\n",
        "        outside_percentages = country_home_analysis['outside_pct']\n",
        "        \n",
        "        plt.bar(range(len(countries)), outside_percentages, alpha=0.7, color='orange')\n",
        "        plt.title('Процент транзакций \"вне родной страны\" по странам\\n(Показывает логику определения домашней страны)')\n",
        "        plt.xlabel('Страны')\n",
        "        plt.ylabel('Процент транзакций \"вне родной страны\" (%)')\n",
        "        plt.xticks(range(len(countries)), countries, rotation=45)\n",
        "        \n",
        "        # Добавляем значения на столбцы\n",
        "        for i, pct in enumerate(outside_percentages):\n",
        "            plt.text(i, pct + 1, f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"\\n2. СТАТИСТИКА:\")\n",
        "        print(f\"Общий процент транзакций 'вне родной страны': {df['is_outside_home_country'].mean()*100:.2f}%\")\n",
        "        \n",
        "        # Проверяем есть ли customer_id для анализа\n",
        "        if 'customer_id' in df.columns:\n",
        "            print(\"\\n3. АНАЛИЗ КЛИЕНТОВ (если данные доступны):\")\n",
        "            # Анализ клиентов по странам\n",
        "            customer_country = df.groupby('customer_id')['country'].nunique().reset_index()\n",
        "            multi_country_customers = customer_country[customer_country['country'] > 1]\n",
        "            print(f\"Клиентов с транзакциями в >1 стране: {len(multi_country_customers):,}\")\n",
        "        \n",
        "        print(f\"\\n4. ГИПОТЕЗА О ЛОГИКЕ ОПРЕДЕЛЕНИЯ:\")\n",
        "        print(\"На основе данных можно предположить, что:\")\n",
        "        if country_home_analysis['outside_pct'].std() > 5:  # Если есть существенная разница между странами\n",
        "            print(\"- Родная страна определяется на основе регистрации клиента/банка\")\n",
        "            print(\"- Каждая страна имеет свою базу клиентов\")\n",
        "            print(\"- is_outside_home_country = True когда клиент совершает транзакцию не в стране регистрации\")\n",
        "        else:\n",
        "            print(\"- Все страны показывают похожий процент - возможно случайное распределение\")\n",
        "            print(\"- Логика может быть основана на других факторах (IP, геолокация и т.д.)\")\n",
        "            \n",
        "    return country_home_analysis\n",
        "\n",
        "def suggest_better_city_analysis(df):\n",
        "    \"\"\"Предлагает более информативные графики вместо простого распределения по размеру города\"\"\"\n",
        "    \n",
        "    print(\"\\n=== АЛЬТЕРНАТИВЫ ДЛЯ АНАЛИЗА ГОРОДОВ ===\")\n",
        "    \n",
        "    if 'city_size' not in df.columns:\n",
        "        print(\"Столбец city_size не найден\")\n",
        "        return\n",
        "    \n",
        "    print(\"Текущий график 'Распределение мошенничества по размеру города' действительно малоинформативен.\")\n",
        "    print(\"Предлагаем следующие альтернативы:\\n\")\n",
        "    \n",
        "    # 1. Fraud rate ratio - сравнение с базовой линией\n",
        "    print(\"1. КОЭФФИЦИЕНТ РИСКА ПО РАЗМЕРУ ГОРОДА\")\n",
        "    \n",
        "    city_fraud = df.groupby('city_size').agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    city_fraud.columns = ['city_size', 'total_transactions', 'fraud_count', 'fraud_rate']\n",
        "    \n",
        "    overall_fraud_rate = df['is_fraud'].mean()\n",
        "    city_fraud['risk_ratio'] = city_fraud['fraud_rate'] / overall_fraud_rate\n",
        "    city_fraud['risk_level'] = city_fraud['risk_ratio'].apply(\n",
        "        lambda x: 'Высокий риск' if x > 1.1 else ('Низкий риск' if x < 0.9 else 'Средний риск')\n",
        "    )\n",
        "    \n",
        "    # График коэффициента риска\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['red' if x > 1.1 else ('green' if x < 0.9 else 'orange') for x in city_fraud['risk_ratio']]\n",
        "    \n",
        "    plt.bar(range(len(city_fraud)), city_fraud['risk_ratio'], color=colors, alpha=0.7)\n",
        "    plt.axhline(y=1.0, color='black', linestyle='--', alpha=0.5, label='Базовая линия (общий fraud rate)')\n",
        "    plt.title('Коэффициент риска мошенничества по размеру города\\n(>1.1 = высокий риск, <0.9 = низкий риск)')\n",
        "    plt.xlabel('Размер города')\n",
        "    plt.ylabel('Коэффициент риска (относительно общего уровня)')\n",
        "    plt.xticks(range(len(city_fraud)), city_fraud['city_size'])\n",
        "    plt.legend()\n",
        "    \n",
        "    # Добавляем значения и статистическую значимость\n",
        "    for i, (ratio, level, count) in enumerate(zip(city_fraud['risk_ratio'], city_fraud['risk_level'], city_fraud['total_transactions'])):\n",
        "        plt.text(i, ratio + 0.05, f'{ratio:.2f}', ha='center', va='bottom', fontsize=10, weight='bold')\n",
        "        plt.text(i, -0.1, f'{level}', ha='center', va='top', fontsize=8, rotation=0)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"РЕЗУЛЬТАТЫ АНАЛИЗА РИСКА:\")\n",
        "    print(city_fraud[['city_size', 'total_transactions', 'fraud_rate', 'risk_ratio', 'risk_level']].to_string(index=False))\n",
        "    \n",
        "    # 2. Временные паттерны по размеру города\n",
        "    if 'hour' in df.columns:\n",
        "        print(f\"\\n2. ВРЕМЕННЫЕ ПАТТЕРНЫ МОШЕННИЧЕСТВА ПО РАЗМЕРУ ГОРОДА\")\n",
        "        \n",
        "        hourly_city_fraud = df.groupby(['city_size', 'hour'])['is_fraud'].mean().reset_index()\n",
        "        hourly_city_pivot = hourly_city_fraud.pivot(index='city_size', columns='hour', values='is_fraud')\n",
        "        \n",
        "        plt.figure(figsize=(16, 6))\n",
        "        sns.heatmap(hourly_city_pivot, annot=False, cmap='Reds', cbar_kws={'label': 'Fraud Rate'})\n",
        "        plt.title('Heatmap: Fraud rate по часам и размеру города')\n",
        "        plt.xlabel('Час дня')\n",
        "        plt.ylabel('Размер города')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # 3. Соотношение каналов по размеру города\n",
        "    if 'channel' in df.columns:\n",
        "        print(f\"\\n3. ПРЕДПОЧТЕНИЯ КАНАЛОВ ПО РАЗМЕРУ ГОРОДА\")\n",
        "        \n",
        "        channel_city = df.groupby(['city_size', 'channel']).size().reset_index(name='count')\n",
        "        channel_city_pct = channel_city.groupby('city_size').apply(\n",
        "            lambda x: x.assign(percentage=x['count']/x['count'].sum()*100)\n",
        "        ).reset_index(drop=True)\n",
        "        \n",
        "        # Создаем stacked bar chart\n",
        "        pivot_channels = channel_city_pct.pivot(index='city_size', columns='channel', values='percentage')\n",
        "        \n",
        "        plt.figure(figsize=(12, 6))\n",
        "        pivot_channels.plot(kind='bar', stacked=True, ax=plt.gca())\n",
        "        plt.title('Распределение каналов транзакций по размеру города (%)')\n",
        "        plt.xlabel('Размер города')\n",
        "        plt.ylabel('Процент использования канала')\n",
        "        plt.legend(title='Канал', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    print(f\"\\n4. РЕКОМЕНДАЦИИ ДЛЯ ЗАМЕНЫ ГРАФИКА:\")\n",
        "    print(\"✓ Используйте коэффициент риска вместо абсолютных чисел\")\n",
        "    print(\"✓ Добавьте временной анализ для выявления паттернов\")\n",
        "    print(\"✓ Проанализируйте поведенческие различия между городами\")\n",
        "    print(\"✓ Включите статистическую значимость различий\")\n",
        "    \n",
        "    return city_fraud\n",
        "\n",
        "# Запуск исследований\n",
        "home_country_analysis = investigate_home_country_logic(df_with_features)\n",
        "better_city_analysis = suggest_better_city_analysis(df_with_features)\n",
        "\n",
        "print(\"\\nИсследование завершено\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10 АЛЬТЕРНАТИВНЫХ ГРАФИКОВ ДЛЯ ЗАМЕНЫ МАЛОИНФОРМАТИВНЫХ\n",
        "def create_alternative_analyses(df):\n",
        "    \"\"\"10 интересных альтернатив для замены простых демографических графиков\"\"\"\n",
        "    \n",
        "    print(\"=== 10 АЛЬТЕРНАТИВНЫХ АНАЛИЗОВ ДЛЯ БИЗНЕСА ===\")\n",
        "    \n",
        "    # 1. RISK SCORE HEAT MAP - Комбинированный анализ рисков\n",
        "    print(\"\\n1. HEATMAP КОМБИНИРОВАННЫХ РИСКОВ\")\n",
        "    \n",
        "    # Создаем risk score на основе нескольких факторов\n",
        "    df_risk = df.copy()\n",
        "    \n",
        "    # Определяем факторы риска\n",
        "    risk_factors = {\n",
        "        'high_amount': df_risk['amount_usd'] > df_risk['amount_usd'].quantile(0.9),\n",
        "        'weekend': df_risk['is_weekend'],\n",
        "        'outside_country': df_risk['is_outside_home_country'],\n",
        "        'night_time': df_risk['hour'].isin([0, 1, 2, 3, 4, 5]),\n",
        "        'high_risk_vendor': df_risk['is_high_risk_vendor']\n",
        "    }\n",
        "    \n",
        "    # Создаем heatmap комбинаций факторов риска\n",
        "    risk_combinations = []\n",
        "    for factor1, condition1 in risk_factors.items():\n",
        "        for factor2, condition2 in risk_factors.items():\n",
        "            if factor1 != factor2:\n",
        "                combined_risk = condition1 & condition2\n",
        "                if combined_risk.sum() > 100:  # Минимум 100 случаев для статистики\n",
        "                    fraud_rate = df_risk[combined_risk]['is_fraud'].mean() * 100\n",
        "                    risk_combinations.append({\n",
        "                        'Factor1': factor1, \n",
        "                        'Factor2': factor2, \n",
        "                        'Count': combined_risk.sum(),\n",
        "                        'Fraud_Rate': fraud_rate\n",
        "                    })\n",
        "    \n",
        "    if risk_combinations:\n",
        "        risk_df = pd.DataFrame(risk_combinations)\n",
        "        risk_pivot = risk_df.pivot(index='Factor1', columns='Factor2', values='Fraud_Rate')\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(risk_pivot, annot=True, fmt='.1f', cmap='Reds', \n",
        "                   cbar_kws={'label': 'Fraud Rate (%)'})\n",
        "        plt.title('Heatmap: Fraud Rate при комбинации факторов риска')\n",
        "        plt.xlabel('Второй фактор риска')\n",
        "        plt.ylabel('Первый фактор риска')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # 2. VELOCITY ANALYSIS - Анализ скорости транзакций\n",
        "    print(\"\\n2. АНАЛИЗ СКОРОСТИ ТРАНЗАКЦИЙ (VELOCITY)\")\n",
        "    \n",
        "    if 'timestamp' in df.columns:\n",
        "        # Сортируем по customer_id и времени (если есть customer_id)\n",
        "        # Иначе анализируем общую скорость по времени\n",
        "        df_velocity = df.copy()\n",
        "        df_velocity = df_velocity.sort_values('timestamp')\n",
        "        df_velocity['hour_group'] = df_velocity['timestamp'].dt.floor('H')\n",
        "        \n",
        "        # Анализ интенсивности транзакций по часам\n",
        "        hourly_intensity = df_velocity.groupby(['hour_group', 'is_fraud']).size().reset_index(name='count')\n",
        "        hourly_pivot = hourly_intensity.pivot(index='hour_group', columns='is_fraud', values='count').fillna(0)\n",
        "        \n",
        "        # Рассчитываем \"скорость мошенничества\"\n",
        "        hourly_pivot['fraud_velocity'] = hourly_pivot[True] / (hourly_pivot[False] + hourly_pivot[True])\n",
        "        \n",
        "        # График скорости мошенничества\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        plt.plot(hourly_pivot.index, hourly_pivot['fraud_velocity'] * 100, \n",
        "                linewidth=2, color='red', alpha=0.7)\n",
        "        plt.title('Скорость мошенничества по времени (Fraud Velocity)')\n",
        "        plt.xlabel('Время')\n",
        "        plt.ylabel('Процент мошеннических транзакций (%)')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # 3. TRANSACTION CLUSTERING - Кластерный анализ поведения\n",
        "    print(\"\\n3. КЛАСТЕРНЫЙ АНАЛИЗ ПОВЕДЕНИЯ ТРАНЗАКЦИЙ\")\n",
        "    \n",
        "    # Создаем признаки для кластеризации\n",
        "    cluster_features = []\n",
        "    if 'amount_usd' in df.columns:\n",
        "        cluster_features.append('amount_usd')\n",
        "    if 'hour' in df.columns:\n",
        "        cluster_features.append('hour')\n",
        "    \n",
        "    if len(cluster_features) >= 2:\n",
        "        from sklearn.cluster import KMeans\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        \n",
        "        # Подготавливаем данные\n",
        "        sample_size = min(10000, len(df))  # Берем выборку для скорости\n",
        "        df_sample = df.sample(n=sample_size, random_state=42)\n",
        "        \n",
        "        features_data = df_sample[cluster_features].fillna(0)\n",
        "        scaler = StandardScaler()\n",
        "        features_scaled = scaler.fit_transform(features_data)\n",
        "        \n",
        "        # Кластеризация\n",
        "        kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "        clusters = kmeans.fit_predict(features_scaled)\n",
        "        df_sample['cluster'] = clusters\n",
        "        \n",
        "        # Анализ fraud rate по кластерам\n",
        "        cluster_analysis = df_sample.groupby('cluster').agg({\n",
        "            'is_fraud': ['count', 'sum', 'mean'],\n",
        "            'amount_usd': 'mean',\n",
        "            'hour': 'mean'\n",
        "        }).round(2)\n",
        "        \n",
        "        cluster_analysis.columns = ['Total', 'Fraud_Count', 'Fraud_Rate', 'Avg_Amount', 'Avg_Hour']\n",
        "        cluster_analysis['Fraud_Rate'] = cluster_analysis['Fraud_Rate'] * 100\n",
        "        \n",
        "        # График кластеров\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        scatter = plt.scatter(df_sample['amount_usd'], df_sample['hour'], \n",
        "                            c=df_sample['cluster'], cmap='viridis', alpha=0.6)\n",
        "        plt.colorbar(scatter, label='Кластер')\n",
        "        plt.xlabel('Сумма транзакции (USD)')\n",
        "        plt.ylabel('Час дня')\n",
        "        plt.title('Кластерный анализ: Группы поведения транзакций')\n",
        "        \n",
        "        # Добавляем информацию о fraud rate для каждого кластера\n",
        "        for cluster_id in range(4):\n",
        "            cluster_data = df_sample[df_sample['cluster'] == cluster_id]\n",
        "            if len(cluster_data) > 0:\n",
        "                mean_amount = cluster_data['amount_usd'].mean()\n",
        "                mean_hour = cluster_data['hour'].mean()\n",
        "                fraud_rate = cluster_data['is_fraud'].mean() * 100\n",
        "                plt.annotate(f'Кластер {cluster_id}\\nFraud: {fraud_rate:.1f}%', \n",
        "                           xy=(mean_amount, mean_hour), \n",
        "                           xytext=(10, 10), textcoords='offset points',\n",
        "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8),\n",
        "                           fontsize=8)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"АНАЛИЗ КЛАСТЕРОВ ПОВЕДЕНИЯ:\")\n",
        "        print(cluster_analysis.to_string())\n",
        "    \n",
        "    # 4. SEQUENTIAL PATTERN ANALYSIS - Анализ последовательных паттернов\n",
        "    print(\"\\n4. АНАЛИЗ ПОСЛЕДОВАТЕЛЬНЫХ ПАТТЕРНОВ\")\n",
        "    \n",
        "    if 'vendor_category' in df.columns:\n",
        "        # Анализ последовательности категорий поставщиков\n",
        "        df_sequential = df.copy()\n",
        "        df_sequential = df_sequential.sort_values('timestamp')\n",
        "        \n",
        "        # Создаем последовательности vendor_category для мошенников vs легитимных\n",
        "        fraud_sequences = df_sequential[df_sequential['is_fraud'] == True]['vendor_category'].value_counts().head(8)\n",
        "        legit_sequences = df_sequential[df_sequential['is_fraud'] == False]['vendor_category'].value_counts().head(8)\n",
        "        \n",
        "        # Сравнительный график популярных категорий\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Мошеннические\n",
        "        ax1.barh(range(len(fraud_sequences)), fraud_sequences.values, color='red', alpha=0.7)\n",
        "        ax1.set_yticks(range(len(fraud_sequences)))\n",
        "        ax1.set_yticklabels(fraud_sequences.index)\n",
        "        ax1.set_title('Популярные категории: Мошеннические транзакции')\n",
        "        ax1.set_xlabel('Количество транзакций')\n",
        "        \n",
        "        # Легитимные\n",
        "        ax2.barh(range(len(legit_sequences)), legit_sequences.values, color='green', alpha=0.7)\n",
        "        ax2.set_yticks(range(len(legit_sequences)))\n",
        "        ax2.set_yticklabels(legit_sequences.index)\n",
        "        ax2.set_title('Популярные категории: Легитимные транзакции')\n",
        "        ax2.set_xlabel('Количество транзакций')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # 5. ANOMALY SCORE DISTRIBUTION - Распределение аномальности\n",
        "    print(\"\\n5. РАСПРЕДЕЛЕНИЕ АНОМАЛЬНОСТИ ТРАНЗАКЦИЙ\")\n",
        "    \n",
        "    # Создаем простой anomaly score\n",
        "    df_anomaly = df.copy()\n",
        "    \n",
        "    # Z-score для суммы\n",
        "    if 'amount_usd' in df.columns:\n",
        "        amount_mean = df_anomaly['amount_usd'].mean()\n",
        "        amount_std = df_anomaly['amount_usd'].std()\n",
        "        df_anomaly['amount_zscore'] = abs((df_anomaly['amount_usd'] - amount_mean) / amount_std)\n",
        "        \n",
        "        # Anomaly score (простая версия)\n",
        "        df_anomaly['anomaly_score'] = df_anomaly['amount_zscore']\n",
        "        \n",
        "        # Добавляем бонусы за другие аномальные факторы\n",
        "        if 'hour' in df.columns:\n",
        "            # Ночное время = аномалия\n",
        "            df_anomaly.loc[df_anomaly['hour'].isin([0, 1, 2, 3, 4, 5]), 'anomaly_score'] += 1\n",
        "        \n",
        "        if 'is_weekend' in df.columns:\n",
        "            # Выходные = небольшая аномалия\n",
        "            df_anomaly.loc[df_anomaly['is_weekend'] == True, 'anomaly_score'] += 0.5\n",
        "        \n",
        "        # Распределение anomaly score для fraud vs non-fraud\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        \n",
        "        fraud_scores = df_anomaly[df_anomaly['is_fraud'] == True]['anomaly_score']\n",
        "        legit_scores = df_anomaly[df_anomaly['is_fraud'] == False]['anomaly_score']\n",
        "        \n",
        "        # Ограничиваем выбросы для лучшей визуализации\n",
        "        score_limit = df_anomaly['anomaly_score'].quantile(0.95)\n",
        "        fraud_scores_limited = fraud_scores[fraud_scores <= score_limit]\n",
        "        legit_scores_limited = legit_scores[legit_scores <= score_limit]\n",
        "        \n",
        "        plt.hist(legit_scores_limited, bins=50, alpha=0.6, label='Легитимные', \n",
        "                color='blue', density=True)\n",
        "        plt.hist(fraud_scores_limited, bins=50, alpha=0.6, label='Мошеннические', \n",
        "                color='red', density=True)\n",
        "        \n",
        "        plt.title('Распределение Anomaly Score: Мошеннические vs Легитимные')\n",
        "        plt.xlabel('Anomaly Score (выше = более аномальная)')\n",
        "        plt.ylabel('Плотность распределения')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Статистика\n",
        "        print(f\"Средний anomaly score (мошеннические): {fraud_scores.mean():.2f}\")\n",
        "        print(f\"Средний anomaly score (легитимные): {legit_scores.mean():.2f}\")\n",
        "        print(f\"Разница: {((fraud_scores.mean() - legit_scores.mean()) / legit_scores.mean() * 100):.1f}%\")\n",
        "    \n",
        "    return df_anomaly\n",
        "\n",
        "# Запуск альтернативных анализов\n",
        "df_with_alternatives = create_alternative_analyses(df_with_features)\n",
        "\n",
        "print(\"\\n=== ДОПОЛНИТЕЛЬНЫЕ ВАРИАНТЫ (6-10) ===\")\n",
        "print(\"6. САНКИ-ДИАГРАММА потоков между странами и каналами\")\n",
        "print(\"7. СЕТЕВОЙ АНАЛИЗ связей между vendor'ами и fraud\")  \n",
        "print(\"8. ВРЕМЕННЫЕ РЯДЫ с сезонностью и трендами\")\n",
        "print(\"9. CORRELATION NETWORK между всеми признаками\")\n",
        "print(\"10. ГЕОГРАФИЧЕСКИЙ АНАЛИЗ с картой fraud hotspots\")\n",
        "print(\"\\nХотите реализовать какие-то из вариантов 6-10?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# НОВЫЕ АНАЛИЗЫ: Замена разделов \"АНАЛИЗ РИСКА ПО РАЗМЕРУ ГОРОДА\" и \"АНАЛИЗ КЛИЕНТОВ ВНЕ РОДНОЙ СТРАНЫ\"\n",
        "\n",
        "# 6. Network graph связей между устройствами и каналами (Санки-диаграмма)\n",
        "def create_sankey_diagram(df):\n",
        "    \"\"\"\n",
        "    Санки-диаграмма: device → channel → vendor_category с толщиной линий пропорциональной fraud rate\n",
        "    \"\"\"\n",
        "    import plotly.graph_objects as go\n",
        "    import numpy as np\n",
        "    \n",
        "    print(\"\\n=== 6. САНКИ-ДИАГРАММА: ОПАСНЫЕ ПУТИ ТРАНЗАКЦИЙ ===\")\n",
        "    \n",
        "    # Агрегируем данные для санки-диаграммы\n",
        "    sankey_data = df.groupby(['device', 'channel', 'vendor_category']).agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean'],\n",
        "        'amount': 'sum'\n",
        "    }).reset_index()\n",
        "    \n",
        "    sankey_data.columns = ['device', 'channel', 'vendor_category', 'total_count', 'fraud_count', 'fraud_rate', 'total_amount']\n",
        "    \n",
        "    # Фильтруем только значимые пути (минимум 100 транзакций)\n",
        "    sankey_data = sankey_data[sankey_data['total_count'] >= 100].copy()\n",
        "    \n",
        "    # Создаем уникальные узлы\n",
        "    devices = sankey_data['device'].unique()\n",
        "    channels = sankey_data['channel'].unique()  \n",
        "    categories = sankey_data['vendor_category'].unique()\n",
        "    \n",
        "    # Создаем маппинг узлов к индексам\n",
        "    all_nodes = list(devices) + list(channels) + list(categories)\n",
        "    node_indices = {node: i for i, node in enumerate(all_nodes)}\n",
        "    \n",
        "    # Создаем связи device → channel\n",
        "    device_channel = sankey_data.groupby(['device', 'channel']).agg({\n",
        "        'total_count': 'sum',\n",
        "        'fraud_rate': 'mean',\n",
        "        'total_amount': 'sum'\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Создаем связи channel → vendor_category\n",
        "    channel_category = sankey_data.groupby(['channel', 'vendor_category']).agg({\n",
        "        'total_count': 'sum', \n",
        "        'fraud_rate': 'mean',\n",
        "        'total_amount': 'sum'\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Подготавливаем данные для Санки\n",
        "    source = []\n",
        "    target = []\n",
        "    value = []\n",
        "    colors = []\n",
        "    \n",
        "    # Device → Channel связи\n",
        "    for _, row in device_channel.iterrows():\n",
        "        source.append(node_indices[row['device']])\n",
        "        target.append(node_indices[row['channel']])\n",
        "        value.append(row['total_count'])\n",
        "        \n",
        "        # Цвет зависит от fraud rate (красный = высокий риск, зеленый = низкий)\n",
        "        if row['fraud_rate'] > 0.05:  # Высокий риск\n",
        "            color = 'rgba(255, 100, 100, 0.6)'\n",
        "        elif row['fraud_rate'] < 0.02:  # Низкий риск\n",
        "            color = 'rgba(100, 255, 100, 0.6)'\n",
        "        else:  # Средний риск\n",
        "            color = 'rgba(255, 200, 100, 0.6)'\n",
        "        colors.append(color)\n",
        "    \n",
        "    # Channel → Category связи\n",
        "    for _, row in channel_category.iterrows():\n",
        "        source.append(node_indices[row['channel']])\n",
        "        target.append(node_indices[row['vendor_category']])\n",
        "        value.append(row['total_count'])\n",
        "        \n",
        "        # Цвет зависит от fraud rate\n",
        "        if row['fraud_rate'] > 0.05:\n",
        "            color = 'rgba(255, 100, 100, 0.6)'\n",
        "        elif row['fraud_rate'] < 0.02:\n",
        "            color = 'rgba(100, 255, 100, 0.6)'\n",
        "        else:\n",
        "            color = 'rgba(255, 200, 100, 0.6)'\n",
        "        colors.append(color)\n",
        "    \n",
        "    # Цвета узлов\n",
        "    node_colors = []\n",
        "    for node in all_nodes:\n",
        "        if node in devices:\n",
        "            node_colors.append('lightblue')\n",
        "        elif node in channels:\n",
        "            node_colors.append('lightgreen')\n",
        "        else:  # categories\n",
        "            node_colors.append('lightcoral')\n",
        "    \n",
        "    # Создаем Санки-диаграмму\n",
        "    fig = go.Figure(data=[go.Sankey(\n",
        "        node=dict(\n",
        "            pad=15,\n",
        "            thickness=20,\n",
        "            line=dict(color=\"black\", width=0.5),\n",
        "            label=all_nodes,\n",
        "            color=node_colors\n",
        "        ),\n",
        "        link=dict(\n",
        "            source=source,\n",
        "            target=target,\n",
        "            value=value,\n",
        "            color=colors\n",
        "        )\n",
        "    )])\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title_text=\"Санки-диаграмма: Device → Channel → Vendor Category<br>(Толщина = объем транзакций, Цвет = уровень риска мошенничества)\",\n",
        "        font_size=12,\n",
        "        height=600\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Статистика по опасным путям\n",
        "    print(\"\\nТОП-10 САМЫХ ОПАСНЫХ ПУТЕЙ (высокий fraud rate):\")\n",
        "    dangerous_paths = sankey_data.nlargest(10, 'fraud_rate')[\n",
        "        ['device', 'channel', 'vendor_category', 'total_count', 'fraud_rate', 'total_amount']\n",
        "    ]\n",
        "    for _, row in dangerous_paths.iterrows():\n",
        "        print(f\"  {row['device']} → {row['channel']} → {row['vendor_category']}\")\n",
        "        print(f\"    Транзакций: {row['total_count']:,}, Fraud rate: {row['fraud_rate']*100:.2f}%, Сумма: ${row['total_amount']:,.0f}\")\n",
        "    \n",
        "    print(f\"\\nОбщий fraud rate по всем путям: {sankey_data['fraud_rate'].mean()*100:.2f}%\")\n",
        "    \n",
        "    return sankey_data\n",
        "\n",
        "# Запускаем анализ\n",
        "if 'device' in df_with_features.columns and 'channel' in df_with_features.columns:\n",
        "    sankey_result = create_sankey_diagram(df_with_features)\n",
        "else:\n",
        "    print(\"Нет данных для санки-диаграммы (отсутствуют поля device/channel)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Survival analysis: время между транзакциями мошенников\n",
        "def analyze_transaction_intervals(df):\n",
        "    \"\"\"\n",
        "    Анализ интервалов между транзакциями для мошеннических vs легитимных аккаунтов\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    from scipy import stats\n",
        "    import seaborn as sns\n",
        "    \n",
        "    print(\"\\n=== 7. SURVIVAL ANALYSIS: ВРЕМЯ МЕЖДУ ТРАНЗАКЦИЯМИ ===\")\n",
        "    \n",
        "    # Сортируем по customer_id и timestamp\n",
        "    df_sorted = df.sort_values(['customer_id', 'timestamp']).copy()\n",
        "    \n",
        "    # Вычисляем интервалы между транзакциями для каждого клиента\n",
        "    df_sorted['prev_timestamp'] = df_sorted.groupby('customer_id')['timestamp'].shift(1)\n",
        "    df_sorted['time_interval_hours'] = (df_sorted['timestamp'] - df_sorted['prev_timestamp']).dt.total_seconds() / 3600\n",
        "    \n",
        "    # Убираем первые транзакции каждого клиента (нет предыдущей транзакции)\n",
        "    intervals_data = df_sorted.dropna(subset=['time_interval_hours']).copy()\n",
        "    \n",
        "    # Ограничиваем интервалы разумными значениями (до 30 дней)\n",
        "    intervals_data = intervals_data[intervals_data['time_interval_hours'] <= 24*30].copy()\n",
        "    \n",
        "    # Разделяем на мошеннические и легитимные аккаунты\n",
        "    fraud_customers = df[df['is_fraud'] == True]['customer_id'].unique()\n",
        "    \n",
        "    fraud_intervals = intervals_data[intervals_data['customer_id'].isin(fraud_customers)]['time_interval_hours']\n",
        "    legit_intervals = intervals_data[~intervals_data['customer_id'].isin(fraud_customers)]['time_interval_hours']\n",
        "    \n",
        "    # Создаем субплоты\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Гистограммы распределений\n",
        "    axes[0,0].hist(legit_intervals, bins=50, alpha=0.7, label='Легитимные', color='green', density=True)\n",
        "    axes[0,0].hist(fraud_intervals, bins=50, alpha=0.7, label='Мошенники', color='red', density=True)\n",
        "    axes[0,0].set_xlabel('Интервал между транзакциями (часы)')\n",
        "    axes[0,0].set_ylabel('Плотность вероятности')\n",
        "    axes[0,0].set_title('Распределение интервалов между транзакциями')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].set_xlim(0, 168)  # Неделя\n",
        "    \n",
        "    # 2. Box plot сравнение\n",
        "    intervals_comparison = [legit_intervals.values, fraud_intervals.values]\n",
        "    axes[0,1].boxplot(intervals_comparison, labels=['Легитимные', 'Мошенники'])\n",
        "    axes[0,1].set_ylabel('Интервал между транзакциями (часы)')\n",
        "    axes[0,1].set_title('Box plot: сравнение интервалов')\n",
        "    axes[0,1].set_yscale('log')\n",
        "    \n",
        "    # 3. Survival curves (доля клиентов, совершающих следующую транзакцию)\n",
        "    time_points = np.logspace(-1, 2, 50)  # От 0.1 до 100 часов\n",
        "    \n",
        "    legit_survival = []\n",
        "    fraud_survival = []\n",
        "    \n",
        "    for t in time_points:\n",
        "        legit_survival.append((legit_intervals <= t).mean())\n",
        "        fraud_survival.append((fraud_intervals <= t).mean())\n",
        "    \n",
        "    axes[1,0].plot(time_points, legit_survival, label='Легитимные', color='green', linewidth=2)\n",
        "    axes[1,0].plot(time_points, fraud_survival, label='Мошенники', color='red', linewidth=2)\n",
        "    axes[1,0].set_xlabel('Время (часы)')\n",
        "    axes[1,0].set_ylabel('Кумулятивная вероятность следующей транзакции')\n",
        "    axes[1,0].set_title('Survival Curves: скорость повторных транзакций')\n",
        "    axes[1,0].set_xscale('log')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Среднее количество транзакций в день по типу клиента\n",
        "    daily_activity = intervals_data.groupby(['customer_id', \n",
        "                                           intervals_data['timestamp'].dt.date]).size().reset_index()\n",
        "    daily_activity.columns = ['customer_id', 'date', 'transactions_per_day']\n",
        "    daily_activity['is_fraud_customer'] = daily_activity['customer_id'].isin(fraud_customers)\n",
        "    \n",
        "    fraud_daily = daily_activity[daily_activity['is_fraud_customer']]['transactions_per_day']\n",
        "    legit_daily = daily_activity[~daily_activity['is_fraud_customer']]['transactions_per_day']\n",
        "    \n",
        "    axes[1,1].hist(legit_daily, bins=30, alpha=0.7, label='Легитимные', color='green', density=True)\n",
        "    axes[1,1].hist(fraud_daily, bins=30, alpha=0.7, label='Мошенники', color='red', density=True)\n",
        "    axes[1,1].set_xlabel('Количество транзакций в день')\n",
        "    axes[1,1].set_ylabel('Плотность вероятности')\n",
        "    axes[1,1].set_title('Активность: транзакций в день')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].set_xlim(0, 20)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Статистический анализ\n",
        "    print(\"\\nСТАТИСТИЧЕСКИЙ АНАЛИЗ:\")\n",
        "    print(f\"Медианный интервал (легитимные): {legit_intervals.median():.1f} часов\")\n",
        "    print(f\"Медианный интервал (мошенники): {fraud_intervals.median():.1f} часов\")\n",
        "    print(f\"Средний интервал (легитимные): {legit_intervals.mean():.1f} часов\")\n",
        "    print(f\"Средний интервал (мошенники): {fraud_intervals.mean():.1f} часов\")\n",
        "    \n",
        "    # Статистический тест\n",
        "    statistic, p_value = stats.mannwhitneyu(fraud_intervals, legit_intervals, alternative='two-sided')\n",
        "    print(f\"\\nMann-Whitney U test p-value: {p_value:.2e}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Статистически значимая разница в интервалах между группами!\")\n",
        "    \n",
        "    # Анализ быстрых повторных транзакций (< 1 час)\n",
        "    quick_legit = (legit_intervals < 1).mean() * 100\n",
        "    quick_fraud = (fraud_intervals < 1).mean() * 100\n",
        "    print(f\"\\nБыстрые повторные транзакции (< 1 час):\")\n",
        "    print(f\"  Легитимные клиенты: {quick_legit:.2f}%\")\n",
        "    print(f\"  Мошенники: {quick_fraud:.2f}%\")\n",
        "    \n",
        "    # Анализ очень активных периодов (> 5 транзакций в день)\n",
        "    hyperactive_legit = (legit_daily > 5).mean() * 100\n",
        "    hyperactive_fraud = (fraud_daily > 5).mean() * 100\n",
        "    print(f\"\\nГиперактивные дни (> 5 транзакций):\")\n",
        "    print(f\"  Легитимные клиенты: {hyperactive_legit:.2f}%\")\n",
        "    print(f\"  Мошенники: {hyperactive_fraud:.2f}%\")\n",
        "    \n",
        "    return {\n",
        "        'fraud_intervals': fraud_intervals,\n",
        "        'legit_intervals': legit_intervals,\n",
        "        'fraud_daily': fraud_daily,\n",
        "        'legit_daily': legit_daily\n",
        "    }\n",
        "\n",
        "# Запускаем анализ\n",
        "if 'timestamp' in df_with_features.columns and 'customer_id' in df_with_features.columns:\n",
        "    survival_result = analyze_transaction_intervals(df_with_features)\n",
        "else:\n",
        "    print(\"Нет данных для survival analysis (отсутствуют поля timestamp/customer_id)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Scatter plot: активность vs размер транзакции\n",
        "def create_activity_amount_scatter(df):\n",
        "    \"\"\"\n",
        "    2D scatter: x = last_hour_activity.num_transactions, y = amount_usd, цвет = fraud/no fraud\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    \n",
        "    print(\"\\n=== 8. SCATTER PLOT: АКТИВНОСТЬ vs РАЗМЕР ТРАНЗАКЦИИ ===\")\n",
        "    \n",
        "    # Проверяем наличие необходимых полей\n",
        "    if 'last_hour_activity' not in df.columns:\n",
        "        print(\"Поле last_hour_activity отсутствует\")\n",
        "        return None\n",
        "        \n",
        "    # Извлекаем данные из структуры last_hour_activity\n",
        "    df_scatter = df.copy()\n",
        "    \n",
        "    # Если last_hour_activity - это структура, извлекаем num_transactions\n",
        "    if hasattr(df_scatter['last_hour_activity'].iloc[0], 'num_transactions'):\n",
        "        df_scatter['num_transactions'] = df_scatter['last_hour_activity'].apply(lambda x: x.num_transactions if x else 0)\n",
        "    else:\n",
        "        # Если это словарь\n",
        "        df_scatter['num_transactions'] = df_scatter['last_hour_activity'].apply(\n",
        "            lambda x: x.get('num_transactions', 0) if isinstance(x, dict) and x else 0\n",
        "        )\n",
        "    \n",
        "    # Используем amount напрямую (конвертируем в USD если есть курсы)\n",
        "    amount_col = 'amount_usd' if 'amount_usd' in df_scatter.columns else 'amount'\n",
        "    \n",
        "    # Фильтруем выбросы для лучшей визуализации\n",
        "    q99_amount = df_scatter[amount_col].quantile(0.99)\n",
        "    q99_activity = df_scatter['num_transactions'].quantile(0.99)\n",
        "    \n",
        "    df_filtered = df_scatter[\n",
        "        (df_scatter[amount_col] <= q99_amount) & \n",
        "        (df_scatter['num_transactions'] <= q99_activity)\n",
        "    ].copy()\n",
        "    \n",
        "    # Создаем scatter plot\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Основной scatter plot\n",
        "    fraud_data = df_filtered[df_filtered['is_fraud'] == True]\n",
        "    legit_data = df_filtered[df_filtered['is_fraud'] == False]\n",
        "    \n",
        "    # Случайная выборка для лучшей визуализации\n",
        "    if len(legit_data) > 5000:\n",
        "        legit_sample = legit_data.sample(n=5000, random_state=42)\n",
        "    else:\n",
        "        legit_sample = legit_data\n",
        "        \n",
        "    axes[0,0].scatter(legit_sample['num_transactions'], legit_sample[amount_col], \n",
        "                     alpha=0.6, c='green', s=20, label='Легитимные')\n",
        "    axes[0,0].scatter(fraud_data['num_transactions'], fraud_data[amount_col], \n",
        "                     alpha=0.8, c='red', s=30, label='Мошенничество')\n",
        "    \n",
        "    axes[0,0].set_xlabel('Количество транзакций за последний час')\n",
        "    axes[0,0].set_ylabel(f'Размер транзакции ({amount_col})')\n",
        "    axes[0,0].set_title('Scatter Plot: Активность vs Размер транзакции')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Heatmap плотности мошенничества\n",
        "    # Создаем сетку для heatmap\n",
        "    x_bins = np.linspace(0, df_filtered['num_transactions'].max(), 20)\n",
        "    y_bins = np.linspace(0, df_filtered[amount_col].max(), 20)\n",
        "    \n",
        "    fraud_rates = []\n",
        "    for i in range(len(x_bins)-1):\n",
        "        row_rates = []\n",
        "        for j in range(len(y_bins)-1):\n",
        "            mask = ((df_filtered['num_transactions'] >= x_bins[i]) & \n",
        "                   (df_filtered['num_transactions'] < x_bins[i+1]) &\n",
        "                   (df_filtered[amount_col] >= y_bins[j]) & \n",
        "                   (df_filtered[amount_col] < y_bins[j+1]))\n",
        "            \n",
        "            if mask.sum() > 10:  # Минимум 10 транзакций в сегменте\n",
        "                fraud_rate = df_filtered[mask]['is_fraud'].mean()\n",
        "            else:\n",
        "                fraud_rate = np.nan\n",
        "            row_rates.append(fraud_rate)\n",
        "        fraud_rates.append(row_rates)\n",
        "    \n",
        "    fraud_rates = np.array(fraud_rates)\n",
        "    \n",
        "    im = axes[0,1].imshow(fraud_rates.T, cmap='Reds', aspect='auto', origin='lower',\n",
        "                         extent=[0, df_filtered['num_transactions'].max(), \n",
        "                                0, df_filtered[amount_col].max()])\n",
        "    axes[0,1].set_xlabel('Количество транзакций за последний час')\n",
        "    axes[0,1].set_ylabel(f'Размер транзакции ({amount_col})')\n",
        "    axes[0,1].set_title('Heatmap: Плотность мошенничества')\n",
        "    plt.colorbar(im, ax=axes[0,1], label='Fraud Rate')\n",
        "    \n",
        "    # 3. Анализ кластеров подозрительного поведения\n",
        "    # Определяем подозрительные зоны\n",
        "    high_activity_threshold = df_filtered['num_transactions'].quantile(0.9)\n",
        "    high_amount_threshold = df_filtered[amount_col].quantile(0.9)\n",
        "    \n",
        "    clusters = {\n",
        "        'Высокая активность + Большая сумма': \n",
        "            (df_filtered['num_transactions'] >= high_activity_threshold) & \n",
        "            (df_filtered[amount_col] >= high_amount_threshold),\n",
        "        'Высокая активность + Малая сумма': \n",
        "            (df_filtered['num_transactions'] >= high_activity_threshold) & \n",
        "            (df_filtered[amount_col] < df_filtered[amount_col].quantile(0.5)),\n",
        "        'Низкая активность + Большая сумма': \n",
        "            (df_filtered['num_transactions'] <= 1) & \n",
        "            (df_filtered[amount_col] >= high_amount_threshold),\n",
        "        'Обычная активность': \n",
        "            (df_filtered['num_transactions'] > 1) & \n",
        "            (df_filtered['num_transactions'] < high_activity_threshold) &\n",
        "            (df_filtered[amount_col] < high_amount_threshold)\n",
        "    }\n",
        "    \n",
        "    cluster_stats = []\n",
        "    colors = ['red', 'orange', 'yellow', 'lightblue']\n",
        "    \n",
        "    for i, (cluster_name, mask) in enumerate(clusters.items()):\n",
        "        cluster_data = df_filtered[mask]\n",
        "        if len(cluster_data) > 0:\n",
        "            fraud_rate = cluster_data['is_fraud'].mean()\n",
        "            cluster_stats.append({\n",
        "                'Кластер': cluster_name,\n",
        "                'Количество': len(cluster_data),\n",
        "                'Fraud Rate': fraud_rate * 100\n",
        "            })\n",
        "            \n",
        "            # Визуализация кластера\n",
        "            axes[1,0].scatter(cluster_data['num_transactions'], cluster_data[amount_col],\n",
        "                             alpha=0.6, c=colors[i], label=f'{cluster_name} ({fraud_rate*100:.1f}%)',\n",
        "                             s=15)\n",
        "    \n",
        "    axes[1,0].set_xlabel('Количество транзакций за последний час')\n",
        "    axes[1,0].set_ylabel(f'Размер транзакции ({amount_col})')\n",
        "    axes[1,0].set_title('Кластеры поведения (с fraud rate)')\n",
        "    axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Статистика по кластерам\n",
        "    import pandas as pd\n",
        "    cluster_df = pd.DataFrame(cluster_stats)\n",
        "    \n",
        "    if not cluster_df.empty:\n",
        "        bars = axes[1,1].bar(range(len(cluster_df)), cluster_df['Fraud Rate'], \n",
        "                            color=colors[:len(cluster_df)], alpha=0.7)\n",
        "        axes[1,1].set_xlabel('Кластеры')\n",
        "        axes[1,1].set_ylabel('Fraud Rate (%)')\n",
        "        axes[1,1].set_title('Fraud Rate по кластерам поведения')\n",
        "        axes[1,1].set_xticks(range(len(cluster_df)))\n",
        "        axes[1,1].set_xticklabels([name[:20] + '...' if len(name) > 20 else name \n",
        "                                  for name in cluster_df['Кластер']], rotation=45)\n",
        "        \n",
        "        # Добавляем значения на столбцы\n",
        "        for i, (bar, rate, count) in enumerate(zip(bars, cluster_df['Fraud Rate'], cluster_df['Количество'])):\n",
        "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                          f'{rate:.1f}%\\n({count:,})', ha='center', va='bottom', fontsize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Выводим статистику\n",
        "    print(\"\\nСТАТИСТИКА ПО КЛАСТЕРАМ:\")\n",
        "    for stat in cluster_stats:\n",
        "        print(f\"  {stat['Кластер']}: {stat['Количество']:,} транзакций, Fraud Rate: {stat['Fraud Rate']:.2f}%\")\n",
        "    \n",
        "    # Корреляционный анализ\n",
        "    correlation = df_filtered[['num_transactions', amount_col, 'is_fraud']].corr()\n",
        "    print(f\"\\nКОРРЕЛЯЦИИ:\")\n",
        "    print(f\"  Активность vs Fraud: {correlation.loc['num_transactions', 'is_fraud']:.3f}\")\n",
        "    print(f\"  Размер транзакции vs Fraud: {correlation.loc[amount_col, 'is_fraud']:.3f}\")\n",
        "    print(f\"  Активность vs Размер: {correlation.loc['num_transactions', amount_col]:.3f}\")\n",
        "    \n",
        "    return {\n",
        "        'cluster_stats': cluster_stats,\n",
        "        'correlation': correlation,\n",
        "        'fraud_rates_grid': fraud_rates\n",
        "    }\n",
        "\n",
        "# Запускаем анализ\n",
        "if 'last_hour_activity' in df_with_features.columns:\n",
        "    activity_result = create_activity_amount_scatter(df_with_features)\n",
        "else:\n",
        "    print(\"Нет данных для scatter plot (отсутствует поле last_hour_activity)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Treemap иерархии рисков\n",
        "def create_risk_hierarchy_treemap(df):\n",
        "    \"\"\"\n",
        "    Древовидная карта: страна → город → канал → тип карты\n",
        "    Размер блока = объем транзакций, цвет = fraud rate\n",
        "    \"\"\"\n",
        "    import plotly.graph_objects as go\n",
        "    import plotly.express as px\n",
        "    import numpy as np\n",
        "    \n",
        "    print(\"\\n=== 10. TREEMAP: ИЕРАРХИЯ РИСКОВ ===\")\n",
        "    \n",
        "    # Агрегируем данные по иерархии\n",
        "    hierarchy_data = df.groupby(['country', 'city_size', 'channel', 'card_type']).agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean'],\n",
        "        'amount': 'sum'\n",
        "    }).reset_index()\n",
        "    \n",
        "    hierarchy_data.columns = ['country', 'city_size', 'channel', 'card_type', \n",
        "                             'total_transactions', 'fraud_count', 'fraud_rate', 'total_amount']\n",
        "    \n",
        "    # Фильтруем только значимые сегменты (минимум 50 транзакций)\n",
        "    hierarchy_data = hierarchy_data[hierarchy_data['total_transactions'] >= 50].copy()\n",
        "    \n",
        "    # Создаем иерархические пути для treemap\n",
        "    hierarchy_data['path'] = (hierarchy_data['country'] + ' / ' + \n",
        "                             hierarchy_data['city_size'] + ' / ' + \n",
        "                             hierarchy_data['channel'] + ' / ' + \n",
        "                             hierarchy_data['card_type'])\n",
        "    \n",
        "    # Создаем родительские узлы\n",
        "    parents = []\n",
        "    ids = []\n",
        "    values = []\n",
        "    colors = []\n",
        "    \n",
        "    # Уровень 1: Страны\n",
        "    country_stats = df.groupby('country').agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean'],\n",
        "        'amount': 'sum'\n",
        "    }).reset_index()\n",
        "    country_stats.columns = ['country', 'total_transactions', 'fraud_count', 'fraud_rate', 'total_amount']\n",
        "    country_stats = country_stats[country_stats['total_transactions'] >= 100]\n",
        "    \n",
        "    for _, row in country_stats.iterrows():\n",
        "        parents.append(\"\")\n",
        "        ids.append(row['country'])\n",
        "        values.append(row['total_transactions'])\n",
        "        colors.append(row['fraud_rate'])\n",
        "    \n",
        "    # Уровень 2: Страна → Размер города\n",
        "    city_stats = df.groupby(['country', 'city_size']).agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean'],\n",
        "        'amount': 'sum'\n",
        "    }).reset_index()\n",
        "    city_stats.columns = ['country', 'city_size', 'total_transactions', 'fraud_count', 'fraud_rate', 'total_amount']\n",
        "    city_stats = city_stats[\n",
        "        (city_stats['total_transactions'] >= 75) & \n",
        "        (city_stats['country'].isin(country_stats['country']))\n",
        "    ]\n",
        "    \n",
        "    for _, row in city_stats.iterrows():\n",
        "        parents.append(row['country'])\n",
        "        ids.append(f\"{row['country']} / {row['city_size']}\")\n",
        "        values.append(row['total_transactions'])\n",
        "        colors.append(row['fraud_rate'])\n",
        "    \n",
        "    # Уровень 3: Страна → Размер города → Канал\n",
        "    channel_stats = df.groupby(['country', 'city_size', 'channel']).agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean'],\n",
        "        'amount': 'sum'\n",
        "    }).reset_index()\n",
        "    channel_stats.columns = ['country', 'city_size', 'channel', 'total_transactions', 'fraud_count', 'fraud_rate', 'total_amount']\n",
        "    channel_stats = channel_stats[channel_stats['total_transactions'] >= 50]\n",
        "    \n",
        "    for _, row in channel_stats.iterrows():\n",
        "        parent_id = f\"{row['country']} / {row['city_size']}\"\n",
        "        if parent_id in ids:\n",
        "            parents.append(parent_id)\n",
        "            ids.append(f\"{row['country']} / {row['city_size']} / {row['channel']}\")\n",
        "            values.append(row['total_transactions'])\n",
        "            colors.append(row['fraud_rate'])\n",
        "    \n",
        "    # Уровень 4: Полная иерархия\n",
        "    for _, row in hierarchy_data.iterrows():\n",
        "        parent_id = f\"{row['country']} / {row['city_size']} / {row['channel']}\"\n",
        "        if parent_id in ids:\n",
        "            parents.append(parent_id)\n",
        "            ids.append(row['path'])\n",
        "            values.append(row['total_transactions'])\n",
        "            colors.append(row['fraud_rate'])\n",
        "    \n",
        "    # Создаем treemap\n",
        "    fig = go.Figure(go.Treemap(\n",
        "        ids=ids,\n",
        "        parents=parents,\n",
        "        values=values,\n",
        "        labels=ids,\n",
        "        marker=dict(\n",
        "            colorscale='RdYlGn_r',  # Красный для высокого риска, зеленый для низкого\n",
        "            colorbar=dict(title=\"Fraud Rate\"),\n",
        "            cmid=df['is_fraud'].mean(),  # Центрируем по общему fraud rate\n",
        "            line=dict(width=2)\n",
        "        ),\n",
        "        textinfo=\"label+value+percent parent\",\n",
        "        hovertemplate='<b>%{label}</b><br>Транзакций: %{value}<br>Fraud Rate: %{color:.3f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=\"Treemap: Иерархия рисков мошенничества<br>Страна → Размер города → Канал → Тип карты<br>(Размер = объем транзакций, Цвет = fraud rate)\",\n",
        "        font_size=12,\n",
        "        height=800\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Альтернативная визуализация - Sunburst chart\n",
        "    fig2 = go.Figure(go.Sunburst(\n",
        "        ids=ids,\n",
        "        parents=parents,\n",
        "        values=values,\n",
        "        labels=ids,\n",
        "        marker=dict(\n",
        "            colorscale='RdYlGn_r',\n",
        "            colorbar=dict(title=\"Fraud Rate\"),\n",
        "            cmid=df['is_fraud'].mean(),\n",
        "            line=dict(width=2)\n",
        "        ),\n",
        "        hovertemplate='<b>%{label}</b><br>Транзакций: %{value}<br>Fraud Rate: %{color:.3f}<extra></extra>'\n",
        "    ))\n",
        "    \n",
        "    fig2.update_layout(\n",
        "        title=\"Sunburst: Иерархическое представление рисков\",\n",
        "        font_size=12,\n",
        "        height=600\n",
        "    )\n",
        "    \n",
        "    fig2.show()\n",
        "    \n",
        "    # Анализ топ рисковых сегментов\n",
        "    print(\"\\nТОП-10 САМЫХ РИСКОВАННЫХ СЕГМЕНТОВ:\")\n",
        "    top_risk = hierarchy_data.nlargest(10, 'fraud_rate')[\n",
        "        ['country', 'city_size', 'channel', 'card_type', 'total_transactions', 'fraud_rate', 'total_amount']\n",
        "    ]\n",
        "    \n",
        "    for _, row in top_risk.iterrows():\n",
        "        print(f\"  {row['country']} → {row['city_size']} → {row['channel']} → {row['card_type']}\")\n",
        "        print(f\"    Транзакций: {row['total_transactions']:,}, Fraud Rate: {row['fraud_rate']*100:.2f}%, Сумма: ${row['total_amount']:,.0f}\")\n",
        "    \n",
        "    # Анализ самых объемных сегментов\n",
        "    print(\"\\nТОП-10 САМЫХ ОБЪЕМНЫХ СЕГМЕНТОВ:\")\n",
        "    top_volume = hierarchy_data.nlargest(10, 'total_transactions')[\n",
        "        ['country', 'city_size', 'channel', 'card_type', 'total_transactions', 'fraud_rate', 'total_amount']\n",
        "    ]\n",
        "    \n",
        "    for _, row in top_volume.iterrows():\n",
        "        print(f\"  {row['country']} → {row['city_size']} → {row['channel']} → {row['card_type']}\")\n",
        "        print(f\"    Транзакций: {row['total_transactions']:,}, Fraud Rate: {row['fraud_rate']*100:.2f}%, Сумма: ${row['total_amount']:,.0f}\")\n",
        "    \n",
        "    # Статистика по уровням иерархии\n",
        "    print(f\"\\nСТАТИСТИКА ПО УРОВНЯМ:\")\n",
        "    print(f\"  Уникальных стран: {len(country_stats)}\")\n",
        "    print(f\"  Уникальных комбинаций страна-город: {len(city_stats)}\")\n",
        "    print(f\"  Уникальных комбинаций страна-город-канал: {len(channel_stats)}\")\n",
        "    print(f\"  Полных иерархических путей: {len(hierarchy_data)}\")\n",
        "    \n",
        "    print(f\"\\nОБЩИЙ FRAUD RATE: {df['is_fraud'].mean()*100:.3f}%\")\n",
        "    print(f\"Максимальный fraud rate в сегменте: {hierarchy_data['fraud_rate'].max()*100:.2f}%\")\n",
        "    print(f\"Минимальный fraud rate в сегменте: {hierarchy_data['fraud_rate'].min()*100:.2f}%\")\n",
        "    \n",
        "    return {\n",
        "        'hierarchy_data': hierarchy_data,\n",
        "        'country_stats': country_stats,\n",
        "        'city_stats': city_stats,\n",
        "        'channel_stats': channel_stats,\n",
        "        'top_risk': top_risk,\n",
        "        'top_volume': top_volume\n",
        "    }\n",
        "\n",
        "# Запускаем анализ\n",
        "required_columns = ['country', 'city_size', 'channel', 'card_type']\n",
        "if all(col in df_with_features.columns for col in required_columns):\n",
        "    treemap_result = create_risk_hierarchy_treemap(df_with_features)\n",
        "else:\n",
        "    missing_cols = [col for col in required_columns if col not in df_with_features.columns]\n",
        "    print(f\"Нет данных для treemap (отсутствуют поля: {missing_cols})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ДОПОЛНИТЕЛЬНЫЙ ГРАФИК: Scatter plot время суток vs объем операций\n",
        "def create_time_amount_scatter(df):\n",
        "    \"\"\"\n",
        "    Scatter plot: ось Y = время суток, ось X = объем денежных операций (amount),\n",
        "    цвет точек = fraud или нет\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    from datetime import datetime\n",
        "    \n",
        "    print(\"\\n=== ДОПОЛНИТЕЛЬНЫЙ SCATTER PLOT: ВРЕМЯ СУТОК vs ОБЪЕМ ОПЕРАЦИЙ ===\")\n",
        "    \n",
        "    # Извлекаем час из timestamp\n",
        "    df_time = df.copy()\n",
        "    df_time['hour'] = df_time['timestamp'].dt.hour\n",
        "    \n",
        "    # Используем amount напрямую\n",
        "    amount_col = 'amount_usd' if 'amount_usd' in df_time.columns else 'amount'\n",
        "    \n",
        "    # Фильтруем выбросы для лучшей визуализации\n",
        "    q99_amount = df_time[amount_col].quantile(0.99)\n",
        "    df_filtered = df_time[df_time[amount_col] <= q99_amount].copy()\n",
        "    \n",
        "    # Создаем субплоты\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Основной scatter plot\n",
        "    fraud_data = df_filtered[df_filtered['is_fraud'] == True]\n",
        "    legit_data = df_filtered[df_filtered['is_fraud'] == False]\n",
        "    \n",
        "    # Случайная выборка для лучшей визуализации\n",
        "    if len(legit_data) > 3000:\n",
        "        legit_sample = legit_data.sample(n=3000, random_state=42)\n",
        "    else:\n",
        "        legit_sample = legit_data\n",
        "    \n",
        "    axes[0,0].scatter(legit_sample[amount_col], legit_sample['hour'], \n",
        "                     alpha=0.5, c='green', s=15, label='Легитимные')\n",
        "    axes[0,0].scatter(fraud_data[amount_col], fraud_data['hour'], \n",
        "                     alpha=0.8, c='red', s=25, label='Мошенничество')\n",
        "    \n",
        "    axes[0,0].set_xlabel(f'Размер транзакции ({amount_col})')\n",
        "    axes[0,0].set_ylabel('Час суток (0-23)')\n",
        "    axes[0,0].set_title('Scatter Plot: Размер транзакции vs Время суток')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    axes[0,0].set_yticks(range(0, 24, 2))\n",
        "    \n",
        "    # 2. Heatmap fraud rate по времени и размеру транзакции\n",
        "    # Создаем бины для времени и суммы\n",
        "    hour_bins = range(0, 25)  # 0-23 часа\n",
        "    amount_bins = np.percentile(df_filtered[amount_col], np.linspace(0, 100, 21))  # 20 бинов по процентилям\n",
        "    \n",
        "    fraud_rates_grid = np.zeros((len(hour_bins)-1, len(amount_bins)-1))\n",
        "    transaction_counts = np.zeros((len(hour_bins)-1, len(amount_bins)-1))\n",
        "    \n",
        "    for i in range(len(hour_bins)-1):\n",
        "        for j in range(len(amount_bins)-1):\n",
        "            mask = ((df_filtered['hour'] >= hour_bins[i]) & \n",
        "                   (df_filtered['hour'] < hour_bins[i+1]) &\n",
        "                   (df_filtered[amount_col] >= amount_bins[j]) & \n",
        "                   (df_filtered[amount_col] < amount_bins[j+1]))\n",
        "            \n",
        "            count = mask.sum()\n",
        "            transaction_counts[i, j] = count\n",
        "            \n",
        "            if count > 10:  # Минимум 10 транзакций в сегменте\n",
        "                fraud_rates_grid[i, j] = df_filtered[mask]['is_fraud'].mean()\n",
        "            else:\n",
        "                fraud_rates_grid[i, j] = np.nan\n",
        "    \n",
        "    # Маскируем области с малым количеством данных\n",
        "    fraud_rates_masked = np.ma.masked_where(transaction_counts < 10, fraud_rates_grid)\n",
        "    \n",
        "    im = axes[0,1].imshow(fraud_rates_masked, cmap='RdYlGn_r', aspect='auto',\n",
        "                         extent=[amount_bins[0], amount_bins[-1], 0, 23])\n",
        "    axes[0,1].set_xlabel(f'Размер транзакции ({amount_col})')\n",
        "    axes[0,1].set_ylabel('Час суток')\n",
        "    axes[0,1].set_title('Heatmap: Fraud Rate по времени и размеру')\n",
        "    axes[0,1].set_yticks(range(0, 24, 2))\n",
        "    plt.colorbar(im, ax=axes[0,1], label='Fraud Rate')\n",
        "    \n",
        "    # 3. Анализ по временным периодам\n",
        "    # Определяем временные периоды\n",
        "    def get_time_period(hour):\n",
        "        if 6 <= hour < 12:\n",
        "            return 'Утро (6-12)'\n",
        "        elif 12 <= hour < 18:\n",
        "            return 'День (12-18)'\n",
        "        elif 18 <= hour < 22:\n",
        "            return 'Вечер (18-22)'\n",
        "        else:\n",
        "            return 'Ночь (22-6)'\n",
        "    \n",
        "    df_filtered['time_period'] = df_filtered['hour'].apply(get_time_period)\n",
        "    \n",
        "    # Определяем категории сумм\n",
        "    def get_amount_category(amount, percentiles):\n",
        "        if amount <= percentiles[25]:\n",
        "            return 'Малая (0-25%)'\n",
        "        elif amount <= percentiles[50]:\n",
        "            return 'Средняя (25-50%)'\n",
        "        elif amount <= percentiles[75]:\n",
        "            return 'Большая (50-75%)'\n",
        "        else:\n",
        "            return 'Очень большая (75-100%)'\n",
        "    \n",
        "    amount_percentiles = df_filtered[amount_col].quantile([0.25, 0.5, 0.75, 1.0])\n",
        "    df_filtered['amount_category'] = df_filtered[amount_col].apply(\n",
        "        lambda x: get_amount_category(x, amount_percentiles)\n",
        "    )\n",
        "    \n",
        "    # Анализ fraud rate по периодам и категориям сумм\n",
        "    time_amount_analysis = df_filtered.groupby(['time_period', 'amount_category']).agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean']\n",
        "    }).reset_index()\n",
        "    time_amount_analysis.columns = ['time_period', 'amount_category', 'total_count', 'fraud_count', 'fraud_rate']\n",
        "    time_amount_analysis = time_amount_analysis[time_amount_analysis['total_count'] >= 20]\n",
        "    \n",
        "    # Pivot для heatmap\n",
        "    pivot_data = time_amount_analysis.pivot(index='time_period', columns='amount_category', values='fraud_rate')\n",
        "    \n",
        "    sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlGn_r', \n",
        "               ax=axes[1,0], cbar_kws={'label': 'Fraud Rate'})\n",
        "    axes[1,0].set_title('Fraud Rate по времени суток и категории суммы')\n",
        "    axes[1,0].set_xlabel('Категория суммы транзакции')\n",
        "    axes[1,0].set_ylabel('Период времени')\n",
        "    \n",
        "    # 4. Распределение транзакций по часам с разделением fraud/legit\n",
        "    hourly_stats = df_filtered.groupby(['hour', 'is_fraud']).size().unstack(fill_value=0)\n",
        "    \n",
        "    width = 0.35\n",
        "    hours = range(24)\n",
        "    \n",
        "    axes[1,1].bar([h - width/2 for h in hours], hourly_stats[False], \n",
        "                 width, label='Легитимные', alpha=0.7, color='green')\n",
        "    axes[1,1].bar([h + width/2 for h in hours], hourly_stats[True], \n",
        "                 width, label='Мошенничество', alpha=0.7, color='red')\n",
        "    \n",
        "    axes[1,1].set_xlabel('Час суток')\n",
        "    axes[1,1].set_ylabel('Количество транзакций')\n",
        "    axes[1,1].set_title('Распределение транзакций по часам')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].set_xticks(range(0, 24, 2))\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Статистический анализ\n",
        "    print(\"\\nАНАЛИЗ ПО ВРЕМЕННЫМ ПЕРИОДАМ:\")\n",
        "    period_stats = df_filtered.groupby('time_period').agg({\n",
        "        'is_fraud': ['count', 'sum', 'mean'],\n",
        "        amount_col: ['mean', 'median']\n",
        "    }).round(3)\n",
        "    period_stats.columns = ['total_count', 'fraud_count', 'fraud_rate', 'avg_amount', 'median_amount']\n",
        "    \n",
        "    for period in period_stats.index:\n",
        "        stats = period_stats.loc[period]\n",
        "        print(f\"  {period}:\")\n",
        "        print(f\"    Транзакций: {stats['total_count']:,}, Fraud rate: {stats['fraud_rate']*100:.2f}%\")\n",
        "        print(f\"    Средняя сумма: ${stats['avg_amount']:,.2f}, Медианная: ${stats['median_amount']:,.2f}\")\n",
        "    \n",
        "    # Анализ самых опасных временных интервалов\n",
        "    hourly_fraud = df_filtered.groupby('hour')['is_fraud'].agg(['count', 'sum', 'mean']).round(3)\n",
        "    hourly_fraud.columns = ['total_count', 'fraud_count', 'fraud_rate']\n",
        "    hourly_fraud = hourly_fraud[hourly_fraud['total_count'] >= 50]  # Минимум 50 транзакций\n",
        "    \n",
        "    print(f\"\\nСАМЫЕ ОПАСНЫЕ ЧАСЫ (топ-5 по fraud rate):\")\n",
        "    top_dangerous_hours = hourly_fraud.nlargest(5, 'fraud_rate')\n",
        "    for hour, row in top_dangerous_hours.iterrows():\n",
        "        print(f\"  {hour:02d}:00 - {row['fraud_rate']*100:.2f}% ({row['fraud_count']}/{row['total_count']})\")\n",
        "    \n",
        "    print(f\"\\nСАМЫЕ БЕЗОПАСНЫЕ ЧАСЫ (топ-5 по fraud rate):\")\n",
        "    top_safe_hours = hourly_fraud.nsmallest(5, 'fraud_rate')\n",
        "    for hour, row in top_safe_hours.iterrows():\n",
        "        print(f\"  {hour:02d}:00 - {row['fraud_rate']*100:.2f}% ({row['fraud_count']}/{row['total_count']})\")\n",
        "    \n",
        "    # Корреляционный анализ\n",
        "    correlation = df_filtered[['hour', amount_col, 'is_fraud']].corr()\n",
        "    print(f\"\\nКОРРЕЛЯЦИИ:\")\n",
        "    print(f\"  Час vs Fraud: {correlation.loc['hour', 'is_fraud']:.3f}\")\n",
        "    print(f\"  Размер транзакции vs Fraud: {correlation.loc[amount_col, 'is_fraud']:.3f}\")\n",
        "    print(f\"  Час vs Размер транзакции: {correlation.loc['hour', amount_col]:.3f}\")\n",
        "    \n",
        "    return {\n",
        "        'period_stats': period_stats,\n",
        "        'hourly_fraud': hourly_fraud,\n",
        "        'time_amount_analysis': time_amount_analysis,\n",
        "        'correlation': correlation,\n",
        "        'top_dangerous_hours': top_dangerous_hours,\n",
        "        'top_safe_hours': top_safe_hours\n",
        "    }\n",
        "\n",
        "# Запускаем анализ\n",
        "if 'timestamp' in df_with_features.columns:\n",
        "    time_amount_result = create_time_amount_scatter(df_with_features)\n",
        "else:\n",
        "    print(\"Нет данных для анализа времени (отсутствует поле timestamp)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ЗАКЛЮЧЕНИЕ ПО НОВЫМ АНАЛИЗАМ\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"РЕЗЮМЕ НОВЫХ АНАЛИЗОВ:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n🔗 6. САНКИ-ДИАГРАММА (Network Graph):\")\n",
        "print(\"   ✅ Показывает 'опасные пути' транзакций: device → channel → vendor_category\")\n",
        "print(\"   ✅ Толщина линий = объем транзакций, цвет = уровень риска мошенничества\")\n",
        "print(\"   ✅ Выявляет комбинации устройств, каналов и категорий с высоким fraud rate\")\n",
        "\n",
        "print(\"\\n⏱️ 7. SURVIVAL ANALYSIS:\")\n",
        "print(\"   ✅ Анализирует интервалы между транзакциями мошенников vs легитимных клиентов\")\n",
        "print(\"   ✅ Включает survival curves, распределения и поведенческие паттерны\")\n",
        "print(\"   ✅ Выявляет различия в активности между типами пользователей\")\n",
        "\n",
        "print(\"\\n📊 8. SCATTER PLOT АКТИВНОСТИ:\")\n",
        "print(\"   ✅ 2D анализ: активность (last_hour_activity) vs размер транзакции\")\n",
        "print(\"   ✅ Включает heatmap плотности мошенничества и кластерный анализ\")\n",
        "print(\"   ✅ Показывает подозрительные паттерны поведения\")\n",
        "\n",
        "print(\"\\n🌳 10. TREEMAP ИЕРАРХИИ РИСКОВ:\")\n",
        "print(\"   ✅ Иерархическая визуализация: страна → город → канал → тип карты\")\n",
        "print(\"   ✅ Размер блока = объем транзакций, цвет = fraud rate\")\n",
        "print(\"   ✅ Дополнительно: Sunburst диаграмма для альтернативного представления\")\n",
        "\n",
        "print(\"\\n🕐 ДОПОЛНИТЕЛЬНЫЙ SCATTER PLOT:\")\n",
        "print(\"   ✅ Время суток vs объем операций с цветовым кодированием fraud/no fraud\")\n",
        "print(\"   ✅ Включает анализ по временным периодам и heatmap рисков\")\n",
        "print(\"   ✅ Выявляет временные паттерны мошенничества\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ЭТИ ГРАФИКИ ЗАМЕНИЛИ:\")\n",
        "print(\"❌ 'АНАЛИЗ РИСКА ПО РАЗМЕРУ ГОРОДА' - заменен на более информативные анализы\")\n",
        "print(\"❌ 'АНАЛИЗ КЛИЕНТОВ ВНЕ РОДНОЙ СТРАНЫ' - заменен на более информативные анализы\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n🎯 КЛЮЧЕВЫЕ ПРЕИМУЩЕСТВА НОВЫХ АНАЛИЗОВ:\")\n",
        "print(\"   • Интерактивные Plotly визуализации (Санки, Treemap, Sunburst)\")\n",
        "print(\"   • Многомерный анализ с несколькими метриками одновременно\")\n",
        "print(\"   • Временной анализ поведенческих паттернов\")\n",
        "print(\"   • Иерархическое представление рисков\")\n",
        "print(\"   • Кластерный анализ подозрительного поведения\")\n",
        "print(\"   • Корреляционный и статистический анализ\")\n",
        "\n",
        "print(\"\\n📈 ПРАКТИЧЕСКАЯ ЦЕННОСТЬ:\")\n",
        "print(\"   • Выявление 'опасных путей' для блокировки\")\n",
        "print(\"   • Определение временных окон повышенного риска\")\n",
        "print(\"   • Сегментация клиентов по уровню активности и риска\")\n",
        "print(\"   • Приоритизация мониторинга по географии и каналам\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
